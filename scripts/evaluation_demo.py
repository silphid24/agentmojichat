#!/usr/bin/env python3
"""
RAG í‰ê°€ ì‹œìŠ¤í…œ ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ ì¸ë±ì‹±ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
"""

import os
import asyncio
import sys
import time
from pathlib import Path
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • - í…”ë ˆë©”íŠ¸ë¦¬ ë° ì—°ê²° ì•ˆì •ì„± ê°œì„ 
os.environ["CHROMA_DISABLE_TELEMETRY"] = "true"
os.environ["CHROMA_TELEMETRY_DISABLED"] = "true"
os.environ["ANONYMIZED_TELEMETRY"] = "false"
os.environ["CHROMA_TELEMETRY"] = "false"
os.environ["CHROMA_CLIENT_TIMEOUT"] = "10"
os.environ["HTTPX_TIMEOUT"] = "30"
os.environ["OPENAI_TIMEOUT"] = "30"

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.rag.enhanced_rag import rag_pipeline
from app.evaluation.ragas_evaluator import RAGASEvaluator
from app.evaluation.metrics_dashboard import MetricsDashboard
from app.evaluation.chunk_quality_evaluator import ChunkQualityEvaluator
from app.evaluation.vectordb_performance_evaluator import VectorDBPerformanceEvaluator
from app.core.logging import logger


async def quick_performance_test():
    """ë¹ ë¥¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ - ì‹¤ì œ ë°ì´í„° ê¸°ë°˜"""
    
    try:
        logger.info("=== ë¹ ë¥¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        # Vector DB ì´ˆê¸°í™” í™•ì¸
        rag_pipeline._initialize_vectorstore()
        
        if not rag_pipeline.vectorstore:
            logger.error("Vector storeê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
            
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš© ì¿¼ë¦¬
        test_queries = [
            "íšŒì‚¬ ì´ë¦„ì´ ë¬´ì—‡ì¸ê°€ìš”?",
            "ê¸‰ì—¬ ì§€ê¸‰ì¼ì€ ì–¸ì œì¸ê°€ìš”?",
            "ì ì‹¬ê°’ ì§€ì›ì€ ì–¼ë§ˆì¸ê°€ìš”?",
            "íšŒì‚¬ì˜ ì£¼ìš” ì‚¬ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì—…ë¬´ ë©”ì‹ ì €ëŠ” ë¬´ì—‡ì„ ì‚¬ìš©í•˜ë‚˜ìš”?"
        ]
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        performance_metrics = {
            "query_times": [],
            "total_time": 0,
            "successful_queries": 0,
            "failed_queries": 0
        }
        
        start_time = time.time()
        
        for query in test_queries:
            query_start = time.time()
            try:
                # Use hybrid search for better performance
                from app.rag.hybrid_search import HybridRAGPipeline
                hybrid_pipeline = HybridRAGPipeline(rag_pipeline)
                result = await hybrid_pipeline.answer_with_hybrid_search(query)
                query_time = time.time() - query_start
                
                performance_metrics["query_times"].append(query_time)
                performance_metrics["successful_queries"] += 1
                
                logger.info(f"Query: {query[:30]}... - Time: {query_time:.3f}s")
                
            except Exception as e:
                performance_metrics["failed_queries"] += 1
                logger.error(f"Query failed: {query[:30]}... - Error: {e}")
        
        performance_metrics["total_time"] = time.time() - start_time
        performance_metrics["avg_query_time"] = sum(performance_metrics["query_times"]) / len(performance_metrics["query_times"]) if performance_metrics["query_times"] else 0
        
        # ê²°ê³¼ ì¶œë ¥
        logger.info("=== ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===")
        logger.info(f"ì´ í…ŒìŠ¤íŠ¸ ì‹œê°„: {performance_metrics['total_time']:.3f}ì´ˆ")
        logger.info(f"í‰ê·  ì¿¼ë¦¬ ì‘ë‹µ ì‹œê°„: {performance_metrics['avg_query_time']:.3f}ì´ˆ")
        logger.info(f"ì„±ê³µ ì¿¼ë¦¬: {performance_metrics['successful_queries']}/{len(test_queries)}")
        logger.info(f"ì‹¤íŒ¨ ì¿¼ë¦¬: {performance_metrics['failed_queries']}/{len(test_queries)}")
        
        return performance_metrics
        
    except Exception as e:
        logger.error(f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


async def run_real_data_evaluation():
    """ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ RAG í‰ê°€ ì‹œìŠ¤í…œ ì‹¤í–‰ (ë©”ì¸ í‰ê°€ í•¨ìˆ˜)"""
    
    try:
        logger.info("=== ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ RAG í‰ê°€ ì‹œìŠ¤í…œ ì‹œì‘ ===")
        
        # 1. ê¸°ì¡´ Vector DB ìƒíƒœ í™•ì¸
        logger.info("1. ê¸°ì¡´ Vector DB ìƒíƒœ í™•ì¸ ì¤‘...")
        rag_pipeline._initialize_vectorstore()
        
        # Vector store í†µê³„ ê°€ì ¸ì˜¤ê¸°
        vectorstore_stats = {}
        total_docs = 0
        
        if rag_pipeline.vectorstore:
            try:
                collection = rag_pipeline.vectorstore._collection
                total_docs = collection.count()
                vectorstore_stats = {
                    "total_documents": total_docs,
                    "collection_name": collection.name if hasattr(collection, 'name') else "unknown"
                }
                logger.info(f"Vector DB ìƒíƒœ: {total_docs}ê°œ ë¬¸ì„œ ì¸ë±ì‹±ë¨")
            except Exception as e:
                logger.warning(f"Vector DB ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        if total_docs == 0:
            logger.warning("Vector DBì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.")
            logger.info("ë¬¸ì„œ ë¡œë“œ ë°©ë²•: python upload_docs.py")
            return {"success": False, "error": "No documents in vector DB"}
        
        # 2. ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ìƒì„±
        logger.info("2. ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì¤€ë¹„ ì¤‘...")
        
        # ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì‹¤ì œ ì¿¼ë¦¬ë“¤
        real_test_queries = [
            # íšŒì‚¬ ì •ë³´
            "íšŒì‚¬ ì´ë¦„ì´ ë¬´ì—‡ì¸ê°€ìš”?",
            "íšŒì‚¬ ì„¤ë¦½ì¼ì€ ì–¸ì œì¸ê°€ìš”?",
            "íšŒì‚¬ ë³¸ì‚¬ ìœ„ì¹˜ëŠ” ì–´ë””ì¸ê°€ìš”?",
            "ëŒ€êµ¬ ì§€ì‚¬ ì£¼ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
            "íšŒì‚¬ì˜ ì£¼ìš” ì‚¬ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            
            # ê¸°ìˆ  ê´€ë ¨
            "ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ëŠ” ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?",
            "ì‚¬ìš©í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ëª¨ë‹ˆí„°ë§ ë„êµ¬ë¡œëŠ” ë¬´ì—‡ì„ ì‚¬ìš©í•˜ë‚˜ìš”?",
            "ë°°í¬ í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?",
            
            # ì¡°ì§ ë° ì¸ì‚¬
            "DXê¸°íšíŒ€ êµ¬ì„±ì›ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "AIoTê°œë°œíŒ€ì—ëŠ” ëˆ„ê°€ ìˆë‚˜ìš”?",
            "ê¸‰ì—¬ ì§€ê¸‰ì¼ì€ ì–¸ì œì¸ê°€ìš”?",
            "ì—°ì°¨ëŠ” ì–´ë–»ê²Œ ê³„ì‚°ë˜ë‚˜ìš”?",
            "í‡´ì‚¬ í†µë³´ëŠ” ì–¸ì œê¹Œì§€ í•´ì•¼ í•˜ë‚˜ìš”?",
            
            # ë³µì§€ ë° í˜œíƒ
            "ìœ ì—°ê·¼ë¬´ì œëŠ” ì–´ë–»ê²Œ ìš´ì˜ë˜ë‚˜ìš”?",
            "ì ì‹¬ê°’ ì§€ì›ì€ ì–¼ë§ˆì¸ê°€ìš”?",
            "ìƒì¼ì¶•í•˜ê¸ˆì€ ì–¼ë§ˆì¸ê°€ìš”?",
            "ê±´ê°•ê²€ì§„ ì§€ì› ë‚´ìš©ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "íšŒì‹ë¹„ ì§€ì›ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            
            # ì—…ë¬´ ë„êµ¬ ë° í”„ë¡œì„¸ìŠ¤
            "ì‚¬ë‚´ ë©”ì¼ ì‹œìŠ¤í…œì€ ë¬´ì—‡ì„ ì‚¬ìš©í•˜ë‚˜ìš”?",
            "ì—…ë¬´ ë©”ì‹ ì €ëŠ” ì–´ë–¤ ê²ƒì„ ì‚¬ìš©í•˜ë‚˜ìš”?",
            "ì½”ë“œ ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "Git ì›Œí¬í”Œë¡œìš°ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "í…ŒìŠ¤íŠ¸ ì •ì±…ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            
            # ë³µí•© ì§ˆë¬¸
            "ì‹ ì… ê°œë°œìê°€ ì•Œì•„ì•¼ í•  ì£¼ìš” ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "íšŒì‚¬ì˜ ê°œë°œ ë¬¸í™”ì™€ í”„ë¡œì„¸ìŠ¤ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "ì˜¨ë³´ë”© í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?",
            "íšŒì‚¬ ë³µë¦¬í›„ìƒ ì œë„ì— ëŒ€í•´ ì „ë°˜ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "HACCP ì»¨ì„¤íŒ…ê³¼ ìŠ¤ë§ˆíŠ¸íŒ©í† ë¦¬ ì‚¬ì—…ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”"
        ]
        
        # 3. RAGAS í‰ê°€ ì‹¤í–‰
        logger.info("3. RAGAS í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        evaluator = RAGASEvaluator(
            rag_pipeline=rag_pipeline,
            results_dir="data/evaluation/real_data",
            use_ragas=True
        )
        
        # í‰ê°€í•  ì¿¼ë¦¬ ìˆ˜ ì„ íƒ (ì„±ëŠ¥ ê³ ë ¤)
        selected_queries = real_test_queries[:20]  # ìƒìœ„ 20ê°œ ì¿¼ë¦¬ í‰ê°€
        
        logger.info(f"4. {len(selected_queries)}ê°œ ì‹¤ì œ ì¿¼ë¦¬ë¡œ í‰ê°€ ì‹¤í–‰ ì¤‘...")
        
        # í‰ê°€ ì‹¤í–‰
        evaluation_results_list, evaluation_summary = await evaluator.evaluate_dataset(selected_queries)
        
        # 5. ì²­í‚¹ í’ˆì§ˆ í‰ê°€ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
        logger.info("5. ì‹¤ì œ ë°ì´í„° ì²­í‚¹ í’ˆì§ˆ í‰ê°€ ì¤‘...")
        
        chunk_quality_metrics = None
        chunk_quality_report = {}
        
        try:
            # ì‹¤ì œ ì²­í¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            chunk_documents = []
            if rag_pipeline.vectorstore and hasattr(rag_pipeline.vectorstore, '_collection'):
                chunks = rag_pipeline.vectorstore._collection.get(include=['documents', 'metadatas'])
                if chunks and chunks.get('documents') and isinstance(chunks['documents'], list):
                    from langchain.schema import Document
                    documents = chunks['documents']
                    metadatas = chunks.get('metadatas', [])
                    
                    # ìƒ˜í”Œë§ (ì„±ëŠ¥ì„ ìœ„í•´ ì¼ë¶€ë§Œ í‰ê°€)
                    sample_size = min(200, len(documents))
                    import random
                    sample_indices = random.sample(range(len(documents)), sample_size)
                    
                    for idx in sample_indices:
                        if idx < len(documents) and isinstance(documents[idx], str):
                            metadata = metadatas[idx] if metadatas and idx < len(metadatas) else {}
                            chunk_documents.append(Document(page_content=documents[idx], metadata=metadata))
            
            if chunk_documents:
                chunk_evaluator = ChunkQualityEvaluator()
                chunk_quality_metrics = chunk_evaluator.evaluate_chunks(chunks=chunk_documents)
                chunk_quality_report = chunk_evaluator.generate_quality_report(chunk_quality_metrics, chunk_documents)
                logger.info(f"ì²­í‚¹ í’ˆì§ˆ í‰ê°€ ì™„ë£Œ: ì „ì²´ í’ˆì§ˆ ì ìˆ˜ {chunk_quality_metrics.overall_quality:.3f}")
            else:
                logger.warning("ì²­í¬ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì²­í‚¹ í’ˆì§ˆ í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"ì²­í‚¹ í’ˆì§ˆ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # 6. Vector DB ì„±ëŠ¥ í‰ê°€ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
        logger.info("6. Vector DB ì„±ëŠ¥ í‰ê°€ ì¤‘...")
        
        vectordb_metrics = None
        vectordb_report = {}
        
        try:
            if rag_pipeline.vectorstore:
                # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš© ì¿¼ë¦¬
                performance_test_queries = [
                    "íšŒì‚¬ ì´ë¦„ì´ ë¬´ì—‡ì¸ê°€ìš”?",
                    "ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    "ì§ì› ë³µë¦¬í›„ìƒì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                    "ê°œë°œ ê°€ì´ë“œì˜ ì£¼ìš” ë‚´ìš©ì€?",
                    "ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ëŠ” ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?",
                    "ì˜¨ë³´ë”© í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                    "í…ŒìŠ¤íŠ¸ ì •ì±…ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    "ë°°í¬ í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?",
                    "ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì€ ë¬´ì—‡ì„ ì‚¬ìš©í•˜ë‚˜ìš”?",
                    "ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì„±ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
                ]
                
                vectordb_evaluator = VectorDBPerformanceEvaluator(
                    vectorstore=rag_pipeline.vectorstore,
                    test_queries=performance_test_queries
                )
                
                vectordb_metrics = vectordb_evaluator.evaluate_performance()
                vectordb_report = vectordb_evaluator.generate_performance_report(vectordb_metrics)
                logger.info(f"Vector DB ì„±ëŠ¥ í‰ê°€ ì™„ë£Œ: ì „ì²´ ì„±ëŠ¥ ì ìˆ˜ {vectordb_metrics.overall_performance:.3f}")
            else:
                logger.warning("Vector storeë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ Vector DB ì„±ëŠ¥ í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"Vector DB ì„±ëŠ¥ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # 7. ì¢…í•© ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
        logger.info("7. ì¢…í•© ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        dashboard = MetricsDashboard(results_dir="data/evaluation/real_data")
        
        # ê¸°ë³¸ ë¦¬í¬íŠ¸ ìƒì„±
        report = dashboard.generate_report(evaluation_results_list, evaluation_summary, save_plots=True)
        
        # ì¢…í•© HTML ë¦¬í¬íŠ¸ ìƒì„±
        enhanced_report = {
            **report,
            "chunk_quality": {
                "metrics": chunk_quality_metrics.to_dict() if chunk_quality_metrics else {},
                "report": chunk_quality_report if chunk_quality_metrics else {},
                "grade": chunk_quality_report.get("summary", {}).get("quality_grade", "Unknown") if chunk_quality_metrics else "N/A"
            },
            "vectordb_performance": {
                "metrics": vectordb_metrics.to_dict() if vectordb_metrics else {},
                "report": vectordb_report,
                "grade": vectordb_report.get("summary", {}).get("performance_grade", "Unknown") if vectordb_metrics else "N/A"
            },
            "evaluation_timestamp": datetime.now().isoformat(),
            "vectorstore_stats": vectorstore_stats
        }
        
        html_report_path = dashboard.create_comprehensive_html_report(
            results=evaluation_results_list,
            summary=evaluation_summary,
            enhanced_report=enhanced_report
        )
        
        # 8. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        logger.info("=== ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ RAG í‰ê°€ ê²°ê³¼ ìš”ì•½ ===")
        
        # RAGAS í‰ê°€ ê²°ê³¼
        logger.info(f"ğŸ“Š RAGAS í‰ê°€ ê²°ê³¼:")
        logger.info(f"  - ì´ ì¿¼ë¦¬ ìˆ˜: {evaluation_summary.total_queries}")
        logger.info(f"  - í‰ê·  ì‹ ë¢°ë„: {evaluation_summary.avg_faithfulness:.3f}")
        logger.info(f"  - í‰ê·  ë‹µë³€ ê´€ë ¨ì„±: {evaluation_summary.avg_answer_relevancy:.3f}")
        logger.info(f"  - í‰ê·  ì»¨í…ìŠ¤íŠ¸ ì •ë°€ë„: {evaluation_summary.avg_context_precision:.3f}")
        logger.info(f"  - í‰ê·  ì‘ë‹µ ì‹œê°„: {evaluation_summary.avg_response_time:.3f}ì´ˆ")
        
        if chunk_quality_metrics:
            logger.info(f"ğŸ“¦ ì²­í‚¹ í’ˆì§ˆ í‰ê°€:")
            logger.info(f"  - ì˜ë¯¸ì  ì¼ê´€ì„±: {chunk_quality_metrics.semantic_coherence:.3f}")
            logger.info(f"  - ê²½ê³„ í’ˆì§ˆ: {chunk_quality_metrics.boundary_quality:.3f}")
            logger.info(f"  - ì •ë³´ ì»¤ë²„ë¦¬ì§€: {chunk_quality_metrics.information_coverage:.3f}")
            logger.info(f"  - ì „ì²´ í’ˆì§ˆ: {chunk_quality_metrics.overall_quality:.3f}")
        
        if vectordb_metrics:
            logger.info(f"ğŸ—ƒï¸ Vector DB ì„±ëŠ¥:")
            logger.info(f"  - ì¸ë±ìŠ¤ í’ˆì§ˆ: {vectordb_metrics.index_quality:.3f}")
            logger.info(f"  - ê²€ìƒ‰ ì •í™•ë„: {vectordb_metrics.search_accuracy:.3f}")
            logger.info(f"  - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: {vectordb_metrics.memory_efficiency:.3f}")
            logger.info(f"  - ì „ì²´ ì„±ëŠ¥: {vectordb_metrics.overall_performance:.3f}")
        
        logger.info(f"ğŸ“„ ìƒì„¸ HTML ë¦¬í¬íŠ¸: {html_report_path}")
        
        # 9. ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì¶”ì²œì‚¬í•­
        logger.info("=== ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ê°œì„  ì¶”ì²œì‚¬í•­ ===")
        
        recommendations = []
        
        # RAGAS ê²°ê³¼ ê¸°ë°˜ ì¶”ì²œ
        if evaluation_summary.avg_faithfulness < 0.8:
            recommendations.append("ğŸ“ ë‹µë³€ì˜ ì •í™•ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ë” ì •í™•í•œ ë¬¸ì„œ ì²­í‚¹ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        if evaluation_summary.avg_answer_relevancy < 0.8:
            recommendations.append("ğŸ¯ ë‹µë³€ ê´€ë ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ì¿¼ë¦¬ ì´í•´ë„ë¥¼ ê°œì„ í•´ì•¼ í•©ë‹ˆë‹¤.")
        if evaluation_summary.avg_context_precision < 0.8:
            recommendations.append("ğŸ” ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ë²¡í„° ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ì„ íŠœë‹í•´ì•¼ í•©ë‹ˆë‹¤.")
        if evaluation_summary.avg_response_time > 3.0:
            recommendations.append("âš¡ ì‘ë‹µ ì‹œê°„ì„ ë‹¨ì¶•í•˜ê¸° ìœ„í•´ ìºì‹± ë˜ëŠ” ì¸ë±ìŠ¤ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ì²­í‚¹ í’ˆì§ˆ ê¸°ë°˜ ì¶”ì²œ
        if chunk_quality_metrics:
            if chunk_quality_metrics.semantic_coherence < 0.8:
                recommendations.append("ğŸ“š ë¬¸ì„œ ì²­í‚¹ ì‹œ ì˜ë¯¸ì  ì¼ê´€ì„±ì„ ê³ ë ¤í•œ ì²­í‚¹ ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤.")
            if chunk_quality_metrics.boundary_quality < 0.8:
                recommendations.append("âœ‚ï¸ ë¬¸ì¥ ë° ë‹¨ë½ ê²½ê³„ë¥¼ ê³ ë ¤í•œ ì²­í‚¹ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # Vector DB ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì²œ
        if vectordb_metrics:
            if vectordb_metrics.search_accuracy < 0.8:
                recommendations.append("ğŸ” Vector DB ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒì„ ìœ„í•´ ì„ë² ë”© ëª¨ë¸ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            if vectordb_metrics.memory_efficiency < 0.8:
                recommendations.append("ğŸ’¾ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ ì„ ìœ„í•´ ì¸ë±ìŠ¤ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            if vectordb_metrics.search_speed < 0.7:
                recommendations.append("ğŸš€ ê²€ìƒ‰ ì†ë„ í–¥ìƒì„ ìœ„í•´ ì¿¼ë¦¬ ìµœì í™” ë˜ëŠ” í•˜ë“œì›¨ì–´ ì—…ê·¸ë ˆì´ë“œë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        
        if recommendations:
            for rec in recommendations:
                logger.info(f"  {rec}")
        else:
            logger.info("  âœ… ëª¨ë“  ì§€í‘œê°€ ì–‘í˜¸í•©ë‹ˆë‹¤! í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")
        
        logger.info("=== ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ RAG í‰ê°€ ì™„ë£Œ ===")
        
        return {
            "success": True,
            "summary": evaluation_summary,
            "evaluation_results": evaluation_results_list,
            "chunk_quality_metrics": chunk_quality_metrics,
            "vectordb_metrics": vectordb_metrics,
            "html_report_path": html_report_path,
            "recommendations": recommendations,
            "vectorstore_stats": vectorstore_stats,
            "enhanced_report": enhanced_report
        }
        
    except Exception as e:
        logger.error(f"ì‹¤ì œ ë°ì´í„° í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


async def run_comprehensive_real_evaluation():
    """ì¢…í•© ì‹¤ì œ ë°ì´í„° í‰ê°€ - ëª¨ë“  í‰ê°€ ì§€í‘œ í¬í•¨"""
    
    try:
        logger.info("=== ì¢…í•© ì‹¤ì œ ë°ì´í„° RAG í‰ê°€ ì‹œì‘ ===")
        
        # 1. Vector DB ìƒíƒœ í™•ì¸ ë° í†µê³„
        logger.info("1. Vector DB ìƒíƒœ í™•ì¸ ì¤‘...")
        rag_pipeline._initialize_vectorstore()
        
        vectorstore_stats = {}
        total_docs = 0
        
        if rag_pipeline.vectorstore:
            try:
                collection = rag_pipeline.vectorstore._collection
                total_docs = collection.count()
                
                # ìƒì„¸ í†µê³„ ìˆ˜ì§‘
                all_chunks = collection.get(include=['documents', 'metadatas'])
                unique_sources = set()
                
                if all_chunks and all_chunks.get('metadatas'):
                    for metadata in all_chunks['metadatas']:
                        if metadata and metadata.get('source'):
                            unique_sources.add(metadata['source'])
                
                vectorstore_stats = {
                    "total_documents": total_docs,
                    "unique_sources": len(unique_sources),
                    "collection_name": collection.name if hasattr(collection, 'name') else "unknown",
                    "sources": list(unique_sources)[:10]  # ìƒìœ„ 10ê°œë§Œ
                }
                
                logger.info(f"Vector DB ìƒíƒœ: {total_docs}ê°œ ë¬¸ì„œ, {len(unique_sources)}ê°œ ì†ŒìŠ¤ íŒŒì¼")
                
            except Exception as e:
                logger.warning(f"Vector DB ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        if total_docs == 0:
            logger.error("Vector DBì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.")
            logger.info("ë¬¸ì„œ ë¡œë“œ ë°©ë²•: python upload_docs.py")
            return {"success": False, "error": "No documents in vector DB"}
        
        # 2. í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì„¸íŠ¸
        logger.info("2. í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì„¸íŠ¸ ì¤€ë¹„ ì¤‘...")
        
        comprehensive_test_queries = [
            # íšŒì‚¬ ê¸°ë³¸ ì •ë³´
            "íšŒì‚¬ ì´ë¦„ì´ ë¬´ì—‡ì¸ê°€ìš”?",
            "íšŒì‚¬ ì„¤ë¦½ì¼ì€ ì–¸ì œì¸ê°€ìš”?",
            "íšŒì‚¬ ë³¸ì‚¬ ìœ„ì¹˜ëŠ” ì–´ë””ì¸ê°€ìš”?",
            "íšŒì‚¬ì˜ ì£¼ìš” ì‚¬ì—… ë¶„ì•¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            
            # ê¸°ìˆ  ë° ê°œë°œ
            "ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ëŠ” ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?",
            "ì‚¬ìš©í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ì½”ë“œ ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "Git ì›Œí¬í”Œë¡œìš°ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ëŠ” ëª‡ í¼ì„¼íŠ¸ ì´ìƒ ìœ ì§€í•´ì•¼ í•˜ë‚˜ìš”?",
            "ë°°í¬ í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?",
            "ëª¨ë‹ˆí„°ë§ ë„êµ¬ë¡œëŠ” ë¬´ì—‡ì„ ì‚¬ìš©í•˜ë‚˜ìš”?",
            
            # ì¡°ì§ ë° ì¸ì‚¬
            "DXê¸°íšíŒ€ êµ¬ì„±ì›ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "AIoTê°œë°œíŒ€ì—ëŠ” ëˆ„ê°€ ìˆë‚˜ìš”?",
            "ê¸‰ì—¬ ì§€ê¸‰ì¼ì€ ì–¸ì œì¸ê°€ìš”?",
            "ì—°ì°¨ëŠ” ì–´ë–»ê²Œ ê³„ì‚°ë˜ë‚˜ìš”?",
            "ë°˜ì°¨ëŠ” ëª‡ ì‹œê°„ ë‹¨ìœ„ì¸ê°€ìš”?",
            "í‡´ì‚¬ í†µë³´ëŠ” ì–¸ì œê¹Œì§€ í•´ì•¼ í•˜ë‚˜ìš”?",
            
            # ë³µì§€ ë° í˜œíƒ
            "ìœ ì—°ê·¼ë¬´ì œëŠ” ì–´ë–»ê²Œ ìš´ì˜ë˜ë‚˜ìš”?",
            "ì ì‹¬ê°’ ì§€ì›ì€ ì–¼ë§ˆì¸ê°€ìš”?",
            "ìƒì¼ì¶•í•˜ê¸ˆì€ ì–¼ë§ˆì¸ê°€ìš”?",
            "ê±´ê°•ê²€ì§„ ì§€ì› ë‚´ìš©ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "íšŒì‹ë¹„ ì§€ì›ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ì—°ì°¨ì œë„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            
            # ì—…ë¬´ ë„êµ¬ ë° í”„ë¡œì„¸ìŠ¤
            "ì‚¬ë‚´ ë©”ì¼ ì‹œìŠ¤í…œì€ ë¬´ì—‡ì„ ì‚¬ìš©í•˜ë‚˜ìš”?",
            "ì—…ë¬´ ë©”ì‹ ì €ëŠ” ì–´ë–¤ ê²ƒì„ ì‚¬ìš©í•˜ë‚˜ìš”?",
            "í”„ë¡œì íŠ¸ ê´€ë¦¬ ë„êµ¬ëŠ” ë¬´ì—‡ì„ ì‚¬ìš©í•˜ë‚˜ìš”?",
            "ë¬¸ì„œí™” ë„êµ¬ëŠ” ë¬´ì—‡ì„ ì‚¬ìš©í•˜ë‚˜ìš”?",
            "í˜‘ì—… ë„êµ¬ëŠ” ë¬´ì—‡ì„ ì‚¬ìš©í•˜ë‚˜ìš”?",
            "ì½”ë“œ í˜•ìƒê´€ë¦¬ëŠ” ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ë‚˜ìš”?",
            
            # ë³µí•© ì§ˆë¬¸
            "ì‹ ì… ê°œë°œìê°€ ì•Œì•„ì•¼ í•  ì£¼ìš” ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "íšŒì‚¬ì˜ ê°œë°œ ë¬¸í™”ì™€ í”„ë¡œì„¸ìŠ¤ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "ì˜¨ë³´ë”© í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?",
            "íšŒì‚¬ì˜ ë³µë¦¬í›„ìƒ ì œë„ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "HACCP ì»¨ì„¤íŒ…ê³¼ ìŠ¤ë§ˆíŠ¸íŒ©í† ë¦¬ ì‚¬ì—…ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì£¼ìš” í”„ë¡œì íŠ¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "íšŒì‚¬ì˜ ë¹„ì „ê³¼ ë¯¸ì…˜ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ê°œë°œìê°€ ì§€ì¼œì•¼ í•  ì½”ë”© í‘œì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì„±ê³¼ í‰ê°€ëŠ” ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?",
            "êµìœ¡ ë° ê²½ë ¥ ê°œë°œ ê¸°íšŒëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?"
        ]
        
        # 3. ëª¨ë“  í‰ê°€ êµ¬ì„± ìš”ì†Œ ì‹¤í–‰
        logger.info("3. ì¢…í•© í‰ê°€ êµ¬ì„± ìš”ì†Œ ì‹¤í–‰ ì¤‘...")
        
        # 3-1. RAGAS í‰ê°€
        logger.info("3-1. RAGAS í‰ê°€ ì‹¤í–‰ ì¤‘...")
        evaluator = RAGASEvaluator(
            rag_pipeline=rag_pipeline,
            results_dir="data/evaluation/comprehensive",
            use_ragas=True
        )
        
        # í‰ê°€í•  ì¿¼ë¦¬ ìˆ˜ ì„ íƒ (ì„±ëŠ¥ ê³ ë ¤)
        selected_queries = comprehensive_test_queries[:30]  # ìƒìœ„ 30ê°œ ì¿¼ë¦¬ í‰ê°€
        
        evaluation_results_list, evaluation_summary = await evaluator.evaluate_dataset(selected_queries)
        
        # 3-2. ì²­í‚¹ í’ˆì§ˆ í‰ê°€
        logger.info("3-2. ì²­í‚¹ í’ˆì§ˆ í‰ê°€ ì‹¤í–‰ ì¤‘...")
        chunk_quality_metrics = None
        chunk_quality_report = {}
        
        try:
            chunk_documents = []
            if rag_pipeline.vectorstore and hasattr(rag_pipeline.vectorstore, '_collection'):
                chunks = rag_pipeline.vectorstore._collection.get(include=['documents', 'metadatas'])
                if chunks and chunks.get('documents') and isinstance(chunks['documents'], list):
                    from langchain.schema import Document
                    documents = chunks['documents']
                    metadatas = chunks.get('metadatas', [])
                    
                    # ì „ì²´ ë°ì´í„°ì—ì„œ ë” ë§ì€ ìƒ˜í”Œ ì¶”ì¶œ
                    sample_size = min(500, len(documents))
                    import random
                    sample_indices = random.sample(range(len(documents)), sample_size)
                    
                    for idx in sample_indices:
                        if idx < len(documents) and isinstance(documents[idx], str):
                            metadata = metadatas[idx] if metadatas and idx < len(metadatas) else {}
                            chunk_documents.append(Document(page_content=documents[idx], metadata=metadata))
            
            if chunk_documents:
                chunk_evaluator = ChunkQualityEvaluator()
                chunk_quality_metrics = chunk_evaluator.evaluate_chunks(chunks=chunk_documents)
                chunk_quality_report = chunk_evaluator.generate_quality_report(chunk_quality_metrics, chunk_documents)
                logger.info(f"ì²­í‚¹ í’ˆì§ˆ í‰ê°€ ì™„ë£Œ: ì „ì²´ í’ˆì§ˆ ì ìˆ˜ {chunk_quality_metrics.overall_quality:.3f}")
                
        except Exception as e:
            logger.error(f"ì²­í‚¹ í’ˆì§ˆ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # 3-3. Vector DB ì„±ëŠ¥ í‰ê°€
        logger.info("3-3. Vector DB ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰ ì¤‘...")
        vectordb_metrics = None
        vectordb_report = {}
        
        try:
            if rag_pipeline.vectorstore:
                # ë‹¤ì–‘í•œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
                performance_test_queries = [
                    "íšŒì‚¬ ì´ë¦„ì´ ë¬´ì—‡ì¸ê°€ìš”?",
                    "ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    "ë³µë¦¬í›„ìƒ ì œë„ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                    "ê°œë°œ í”„ë¡œì„¸ìŠ¤ì™€ ë°©ë²•ë¡ ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                    "ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ”?",
                    "ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ì™€ êµ¬ì¡°ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                    "ë³´ì•ˆ ì •ì±…ê³¼ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                    "ë¹„ìƒ ëŒ€ì‘ ê³„íšì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                    "í’ˆì§ˆ ë³´ì¦ í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                    "ê³ ê° ì§€ì› í”„ë¡œì„¸ìŠ¤ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                    "ì„±ê³¼ ì¸¡ì • ì§€í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                    "íŒ€ êµ¬ì„±ê³¼ ì—­í• ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                    "ê¸°ìˆ  ë¡œë“œë§µì€ ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?",
                    "íŒŒíŠ¸ë„ˆì‹­ê³¼ í˜‘ë ¥ ê´€ê³„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                    "íšŒì‚¬ì˜ ê²½ìŸ ìš°ìœ„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
                ]
                
                vectordb_evaluator = VectorDBPerformanceEvaluator(
                    vectorstore=rag_pipeline.vectorstore,
                    test_queries=performance_test_queries
                )
                
                vectordb_metrics = vectordb_evaluator.evaluate_performance()
                vectordb_report = vectordb_evaluator.generate_performance_report(vectordb_metrics)
                logger.info(f"Vector DB ì„±ëŠ¥ í‰ê°€ ì™„ë£Œ: ì „ì²´ ì„±ëŠ¥ ì ìˆ˜ {vectordb_metrics.overall_performance:.3f}")
                
        except Exception as e:
            logger.error(f"Vector DB ì„±ëŠ¥ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # 3-4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        logger.info("3-4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        hybrid_performance = await test_hybrid_search_performance()
        
        # 4. ì¢…í•© ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
        logger.info("4. ì¢…í•© ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        dashboard = MetricsDashboard(results_dir="data/evaluation/comprehensive")
        
        # ê¸°ë³¸ ë¦¬í¬íŠ¸ ìƒì„±
        report = dashboard.generate_report(evaluation_results_list, evaluation_summary, save_plots=True)
        
        # ì¢…í•© HTML ë¦¬í¬íŠ¸ ìƒì„±
        enhanced_report = {
            **report,
            "chunk_quality": {
                "metrics": chunk_quality_metrics.to_dict() if chunk_quality_metrics else {},
                "report": chunk_quality_report if chunk_quality_metrics else {},
                "grade": chunk_quality_report.get("summary", {}).get("quality_grade", "Unknown") if chunk_quality_metrics else "N/A"
            },
            "vectordb_performance": {
                "metrics": vectordb_metrics.to_dict() if vectordb_metrics else {},
                "report": vectordb_report,
                "grade": vectordb_report.get("summary", {}).get("performance_grade", "Unknown") if vectordb_metrics else "N/A"
            },
            "hybrid_search_performance": hybrid_performance,
            "evaluation_timestamp": datetime.now().isoformat(),
            "vectorstore_stats": vectorstore_stats
        }
        
        html_report_path = dashboard.create_comprehensive_html_report(
            results=evaluation_results_list,
            summary=evaluation_summary,
            enhanced_report=enhanced_report
        )
        
        # 5. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        logger.info("=== ì¢…í•© ì‹¤ì œ ë°ì´í„° RAG í‰ê°€ ê²°ê³¼ ìš”ì•½ ===")
        
        # Vector DB í†µê³„
        logger.info(f"ğŸ—„ï¸ Vector DB í†µê³„:")
        logger.info(f"  - ì´ ë¬¸ì„œ ìˆ˜: {vectorstore_stats.get('total_documents', 0)}")
        logger.info(f"  - ê³ ìœ  ì†ŒìŠ¤ íŒŒì¼ ìˆ˜: {vectorstore_stats.get('unique_sources', 0)}")
        
        # RAGAS í‰ê°€ ê²°ê³¼
        logger.info(f"ğŸ“Š RAGAS í‰ê°€ ê²°ê³¼:")
        logger.info(f"  - ì´ ì¿¼ë¦¬ ìˆ˜: {evaluation_summary.total_queries}")
        logger.info(f"  - í‰ê·  ì‹ ë¢°ë„: {evaluation_summary.avg_faithfulness:.3f}")
        logger.info(f"  - í‰ê·  ë‹µë³€ ê´€ë ¨ì„±: {evaluation_summary.avg_answer_relevancy:.3f}")
        logger.info(f"  - í‰ê·  ì»¨í…ìŠ¤íŠ¸ ì •ë°€ë„: {evaluation_summary.avg_context_precision:.3f}")
        logger.info(f"  - í‰ê·  ì‘ë‹µ ì‹œê°„: {evaluation_summary.avg_response_time:.3f}ì´ˆ")
        
        if chunk_quality_metrics:
            logger.info(f"ğŸ“¦ ì²­í‚¹ í’ˆì§ˆ í‰ê°€:")
            logger.info(f"  - ì˜ë¯¸ì  ì¼ê´€ì„±: {chunk_quality_metrics.semantic_coherence:.3f}")
            logger.info(f"  - ê²½ê³„ í’ˆì§ˆ: {chunk_quality_metrics.boundary_quality:.3f}")
            logger.info(f"  - ì •ë³´ ì»¤ë²„ë¦¬ì§€: {chunk_quality_metrics.information_coverage:.3f}")
            logger.info(f"  - ì „ì²´ í’ˆì§ˆ: {chunk_quality_metrics.overall_quality:.3f}")
            logger.info(f"  - í’ˆì§ˆ ë“±ê¸‰: {chunk_quality_report.get('summary', {}).get('quality_grade', 'N/A')}")
        
        if vectordb_metrics:
            logger.info(f"ğŸ—ƒï¸ Vector DB ì„±ëŠ¥:")
            logger.info(f"  - ì¸ë±ìŠ¤ í’ˆì§ˆ: {vectordb_metrics.index_quality:.3f}")
            logger.info(f"  - ê²€ìƒ‰ ì •í™•ë„: {vectordb_metrics.search_accuracy:.3f}")
            logger.info(f"  - ê²€ìƒ‰ ì†ë„: {vectordb_metrics.search_speed:.3f}")
            logger.info(f"  - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: {vectordb_metrics.memory_efficiency:.3f}")
            logger.info(f"  - ì „ì²´ ì„±ëŠ¥: {vectordb_metrics.overall_performance:.3f}")
            logger.info(f"  - ì„±ëŠ¥ ë“±ê¸‰: {vectordb_report.get('summary', {}).get('performance_grade', 'N/A')}")
        
        if hybrid_performance:
            logger.info(f"ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥:")
            logger.info(f"  - í‰ê·  ì‘ë‹µ ì‹œê°„: {hybrid_performance.get('avg_query_time', 0):.3f}ì´ˆ")
            logger.info(f"  - ì„±ê³µë¥ : {hybrid_performance.get('successful_queries', 0)}/{hybrid_performance.get('total_queries', 0)}")
        
        logger.info(f"ğŸ“„ ìƒì„¸ HTML ë¦¬í¬íŠ¸: {html_report_path}")
        
        # 6. ì¢…í•© ê°œì„  ì¶”ì²œì‚¬í•­
        recommendations = generate_comprehensive_recommendations(
            evaluation_summary, chunk_quality_metrics, vectordb_metrics, hybrid_performance
        )
        
        if recommendations:
            logger.info("=== ì¢…í•© ê°œì„  ì¶”ì²œì‚¬í•­ ===")
            for i, rec in enumerate(recommendations, 1):
                logger.info(f"{i}. {rec}")
        else:
            logger.info("=== ëª¨ë“  ì§€í‘œê°€ ìš°ìˆ˜í•©ë‹ˆë‹¤! ===")
        
        logger.info("=== ì¢…í•© ì‹¤ì œ ë°ì´í„° RAG í‰ê°€ ì™„ë£Œ ===")
        
        return {
            "success": True,
            "summary": evaluation_summary,
            "evaluation_results": evaluation_results_list,
            "chunk_quality_metrics": chunk_quality_metrics,
            "vectordb_metrics": vectordb_metrics,
            "hybrid_performance": hybrid_performance,
            "html_report_path": html_report_path,
            "recommendations": recommendations,
            "vectorstore_stats": vectorstore_stats,
            "enhanced_report": enhanced_report
        }
        
    except Exception as e:
        logger.error(f"ì¢…í•© ì‹¤ì œ ë°ì´í„° í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


async def test_hybrid_search_performance():
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    try:
        from app.rag.hybrid_search import HybridRAGPipeline
        hybrid_pipeline = HybridRAGPipeline(rag_pipeline)
        
        test_queries = [
            "íšŒì‚¬ì˜ ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì§ì› ë³µë¦¬í›„ìƒ ì œë„ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "ê°œë°œ í”„ë¡œì„¸ìŠ¤ì™€ ì½”ë“œ ë¦¬ë·° ì ˆì°¨ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "ì˜¨ë³´ë”© í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?",
            "íšŒì‚¬ì˜ ë¹„ì „ê³¼ ë¯¸ì…˜ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        ]
        
        performance_metrics = {
            "query_times": [],
            "total_queries": len(test_queries),
            "successful_queries": 0,
            "failed_queries": 0
        }
        
        start_time = time.time()
        
        for query in test_queries:
            query_start = time.time()
            try:
                result = await hybrid_pipeline.answer_with_hybrid_search(query)
                query_time = time.time() - query_start
                
                performance_metrics["query_times"].append(query_time)
                performance_metrics["successful_queries"] += 1
                
            except Exception as e:
                performance_metrics["failed_queries"] += 1
                logger.error(f"Hybrid search failed for query: {query[:50]}... - Error: {e}")
        
        performance_metrics["total_time"] = time.time() - start_time
        performance_metrics["avg_query_time"] = sum(performance_metrics["query_times"]) / len(performance_metrics["query_times"]) if performance_metrics["query_times"] else 0
        
        return performance_metrics
        
    except Exception as e:
        logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return None


def generate_comprehensive_recommendations(evaluation_summary, chunk_quality_metrics, vectordb_metrics, hybrid_performance):
    """ì¢…í•©ì ì¸ ê°œì„  ì¶”ì²œì‚¬í•­ ìƒì„±"""
    recommendations = []
    
    # RAGAS ê²°ê³¼ ê¸°ë°˜ ì¶”ì²œ
    if evaluation_summary:
        if evaluation_summary.avg_faithfulness < 0.85:
            recommendations.append("ğŸ“ ë‹µë³€ì˜ ì •í™•ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ë¬¸ì„œ ì²­í‚¹ ì „ëµì„ ê°œì„ í•˜ê³  ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ìµœì í™”í•˜ì„¸ìš”.")
        if evaluation_summary.avg_answer_relevancy < 0.85:
            recommendations.append("ğŸ¯ ì¿¼ë¦¬ ì´í•´ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ì¿¼ë¦¬ ì¬ì‘ì„±(query rewriting) ê¸°ëŠ¥ì„ ê°œì„ í•˜ì„¸ìš”.")
        if evaluation_summary.avg_context_precision < 0.8:
            recommendations.append("ğŸ” ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ê³  ë¦¬ë­í‚¹ ì•Œê³ ë¦¬ì¦˜ì„ ìµœì í™”í•˜ì„¸ìš”.")
        if evaluation_summary.avg_response_time > 2.5:
            recommendations.append("âš¡ ì‘ë‹µ ì‹œê°„ì„ ë‹¨ì¶•í•˜ê¸° ìœ„í•´ ì¿¼ë¦¬ ìºì‹±, ì¸ë±ìŠ¤ ìµœì í™”, ë° ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ê°•í™”í•˜ì„¸ìš”.")
    
    # ì²­í‚¹ í’ˆì§ˆ ê¸°ë°˜ ì¶”ì²œ
    if chunk_quality_metrics:
        if chunk_quality_metrics.semantic_coherence < 0.85:
            recommendations.append("ğŸ“š ì˜ë¯¸ì  ì¼ê´€ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ë¬¸ì„œì˜ ë…¼ë¦¬ì  êµ¬ì¡°ë¥¼ ê³ ë ¤í•œ ì§€ëŠ¥í˜• ì²­í‚¹ ì•Œê³ ë¦¬ì¦˜ì„ ë„ì…í•˜ì„¸ìš”.")
        if chunk_quality_metrics.boundary_quality < 0.8:
            recommendations.append("âœ‚ï¸ ë¬¸ì¥ ë° ë‹¨ë½ ê²½ê³„ ì¸ì‹ì„ ê°œì„ í•˜ì—¬ ë” ìì—°ìŠ¤ëŸ¬ìš´ ì²­í¬ ë¶„í• ì„ êµ¬í˜„í•˜ì„¸ìš”.")
        if chunk_quality_metrics.size_consistency < 0.7:
            recommendations.append("ğŸ“ ì²­í¬ í¬ê¸°ì˜ ì¼ê´€ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ë™ì  ì²­í¬ í¬ê¸° ì¡°ì • ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì„¸ìš”.")
    
    # Vector DB ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì²œ
    if vectordb_metrics:
        if vectordb_metrics.search_accuracy < 0.85:
            recommendations.append("ğŸ” ë²¡í„° ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ì„ë² ë”© ëª¨ë¸ì„ ë” ê°•ë ¥í•œ ëª¨ë¸ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ê±°ë‚˜ íŒŒì¸íŠœë‹í•˜ì„¸ìš”.")
        if vectordb_metrics.memory_efficiency < 0.75:
            recommendations.append("ğŸ’¾ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë²¡í„° ì°¨ì› ì¶•ì†Œ(PCA, LSH) ë˜ëŠ” ì¸ë±ìŠ¤ í”„ë£¨ë‹ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        if vectordb_metrics.search_speed < 0.75:
            recommendations.append("ğŸš€ ê²€ìƒ‰ ì†ë„ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ HNSW, IVF ë“±ì˜ ê³ ê¸‰ ì¸ë±ì‹± ê¸°ë²•ì„ ì ìš©í•˜ì„¸ìš”.")
        if vectordb_metrics.index_quality < 0.8:
            recommendations.append("ğŸ—ºï¸ ì¸ë±ìŠ¤ í’ˆì§ˆì„ ê°œì„ í•˜ê¸° ìœ„í•´ ì£¼ê¸°ì ì¸ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•ê³¼ í´ëŸ¬ìŠ¤í„°ë§ ìµœì í™”ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.")
    
    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì²œ
    if hybrid_performance and hybrid_performance.get('avg_query_time', 0) > 3.0:
        recommendations.append("ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ê°•í™”í•˜ê³  ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ì•Œê³ ë¦¬ì¦˜ì„ ìµœì í™”í•˜ì„¸ìš”.")
    
    # ì¢…í•©ì  ì¶”ì²œ
    if len(recommendations) > 5:
        recommendations.insert(0, "ğŸŒŸ ì „ë°˜ì ì¸ ì‹œìŠ¤í…œ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ ë‹¨ê³„ì  ê°œì„  ê³„íšì„ ìˆ˜ë¦½í•˜ê³  ê° ê°œì„  ì‚¬í•­ì˜ íš¨ê³¼ë¥¼ ì¸¡ì •í•˜ì„¸ìš”.")
    
    return recommendations


async def quick_single_query_test():
    """ë‹¨ì¼ ì¿¼ë¦¬ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸"""

    try:
        logger.info("=== ë‹¨ì¼ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ===")

        # í‰ê°€ê¸° ì´ˆê¸°í™”
        evaluator = RAGASEvaluator(rag_pipeline=rag_pipeline, use_ragas=True)

        # ë‹¨ì¼ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
        test_query = "íšŒì‚¬ì˜ ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€ ë¬´ì—‡ì¸ê°€ìš”?"
        result = await evaluator.evaluate_single_query(
            query=test_query,
            ground_truth="Python, FastAPI, LangChain, RAG ì‹œìŠ¤í…œ, PostgreSQL, Redis, Docker, Kubernetes",
        )

        # ê²°ê³¼ ì¶œë ¥
        logger.info(f"ì§ˆë¬¸: {result.query}")
        logger.info(f"ë‹µë³€: {result.answer}")
        logger.info(f"ì‹ ë¢°ë„: {result.faithfulness:.3f}")
        logger.info(f"ë‹µë³€ ê´€ë ¨ì„±: {result.answer_relevancy:.3f}")
        logger.info(f"ì»¨í…ìŠ¤íŠ¸ ì •ë°€ë„: {result.context_precision:.3f}")
        logger.info(f"ì‘ë‹µ ì‹œê°„: {result.response_time:.3f}ì´ˆ")
        logger.info(f"ì‚¬ìš©ëœ ëª¨ë¸: {result.model_used}")
        logger.info(f"ì²­í‚¹ ì „ëµ: {result.chunking_strategy}")

        return result

    except Exception as e:
        logger.error(f"ë‹¨ì¼ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return None


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""

    # ì‹¤í–‰ ì˜µì…˜ í™•ì¸
    if len(sys.argv) > 1:
        option = sys.argv[1]
        if option == "quick":
            # ë¹ ë¥¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            await quick_performance_test()
        elif option == "single":
            # ë‹¨ì¼ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
            await quick_single_query_test()
        elif option == "full":
            # ì¢…í•© í‰ê°€
            result = await run_comprehensive_real_evaluation()
            
            if result and result.get("success"):
                print(f"\nâœ… ì¢…í•© í‰ê°€ ì™„ë£Œ! HTML ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”: {result['html_report_path']}")
                print("ğŸ“Š í‰ê°€ ê²°ê³¼:")
                if result.get("summary"):
                    print(f"   RAGAS í‰ê·  ì‹ ë¢°ë„: {result['summary'].avg_faithfulness:.3f}")
                if result.get("chunk_quality_metrics"):
                    print(f"   ì²­í‚¹ í’ˆì§ˆ ì ìˆ˜: {result['chunk_quality_metrics'].overall_quality:.3f}")
                if result.get("vectordb_metrics"):
                    print(f"   Vector DB ì„±ëŠ¥: {result['vectordb_metrics'].overall_performance:.3f}")
                
                # ì¶”ì²œì‚¬í•­ ì¶œë ¥
                if result.get("recommendations"):
                    print("\nğŸ”§ ê°œì„  ì¶”ì²œì‚¬í•­:")
                    for rec in result["recommendations"]:
                        print(f"   {rec}")
            else:
                print(f"\nâŒ ì¢…í•© í‰ê°€ ì‹¤íŒ¨: {result.get('error') if result else 'Unknown error'}")
        else:
            print("ì‚¬ìš©ë²•: python evaluation_demo.py [quick|single|full]")
            print("  quick: ë¹ ë¥¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
            print("  single: ë‹¨ì¼ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸")
            print("  full: ì¢…í•© í‰ê°€ (ì²­í‚¹ í’ˆì§ˆ + Vector DB ì„±ëŠ¥ + RAGAS)")
            print("  (ì˜µì…˜ ì—†ìŒ): ê¸°ë³¸ ì‹¤ì œ ë°ì´í„° í‰ê°€")
    else:
        # ê¸°ë³¸ ì‹¤ì œ ë°ì´í„° í‰ê°€
        result = await run_real_data_evaluation()

        if result and result.get("success"):
            print(f"\nâœ… í‰ê°€ ì™„ë£Œ! HTML ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”: {result['html_report_path']}")
            print("ğŸ“Š í‰ê°€ ê²°ê³¼:")
            if result.get("summary"):
                print(f"   RAGAS í‰ê·  ì‹ ë¢°ë„: {result['summary'].avg_faithfulness:.3f}")
            if result.get("chunk_quality_metrics"):
                print(f"   ì²­í‚¹ í’ˆì§ˆ ì ìˆ˜: {result['chunk_quality_metrics'].overall_quality:.3f}")
            if result.get("vectordb_metrics"):
                print(f"   Vector DB ì„±ëŠ¥: {result['vectordb_metrics'].overall_performance:.3f}")
            
            # ì¶”ì²œì‚¬í•­ ì¶œë ¥
            if result.get("recommendations"):
                print("\nğŸ”§ ê°œì„  ì¶”ì²œì‚¬í•­:")
                for rec in result["recommendations"]:
                    print(f"   {rec}")
        else:
            print(f"\nâŒ í‰ê°€ ì‹¤íŒ¨: {result.get('error') if result else 'Unknown error'}")


if __name__ == "__main__":
    asyncio.run(main())