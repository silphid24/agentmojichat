"""Web Chat adapter implementation with WebSocket support."""

import asyncio
import uuid
from typing import Any, Dict, Optional
from datetime import datetime

from fastapi import WebSocket, WebSocketDisconnect

from .base import (
    BaseAdapter,
    PlatformMessage,
    MessageType,
    User,
    Conversation,
    Attachment,
    AttachmentType,
)


class WebChatConnection:
    """Represents a WebChat connection."""

    def __init__(self, websocket: WebSocket, user_id: str, session_id: str):
        self.websocket = websocket
        self.user_id = user_id
        self.session_id = session_id
        self.connected_at = datetime.utcnow()
        self.last_activity = datetime.utcnow()

    async def send(self, data: Dict[str, Any]) -> None:
        """Send data through WebSocket."""
        await self.websocket.send_json(data)
        self.last_activity = datetime.utcnow()


class WebChatAdapter(BaseAdapter):
    """Web Chat adapter for embedded widget."""

    def __init__(self, config: Dict[str, Any]):
        """Initialize WebChat adapter."""
        super().__init__(config)
        self.connections: Dict[str, WebChatConnection] = {}
        self.conversations: Dict[str, Conversation] = {}
        self.widget_config = config.get("widget", {})
        self._cleanup_task: Optional[asyncio.Task] = None
        self.conversation_agent = None  # Will be set by the router

    async def connect(self) -> None:
        """Start WebChat service."""
        # Start connection cleanup task
        self._cleanup_task = asyncio.create_task(self._cleanup_inactive_connections())

    async def disconnect(self) -> None:
        """Stop WebChat service."""
        # Cancel cleanup task
        if self._cleanup_task:
            self._cleanup_task.cancel()
            try:
                await self._cleanup_task
            except asyncio.CancelledError:
                pass

        # Close all connections
        for conn in list(self.connections.values()):
            await conn.websocket.close()

        self.connections.clear()
        self.conversations.clear()

    async def handle_websocket(
        self, websocket: WebSocket, session_id: Optional[str] = None
    ) -> None:
        """Handle incoming WebSocket connection."""
        await websocket.accept()
        print("[WebChat] WebSocket connection accepted")

        # Generate session ID if not provided
        if not session_id:
            session_id = str(uuid.uuid4())
            print(f"[WebChat] Generated session ID: {session_id}")

        # Wait for authentication message with timeout
        try:
            print("[WebChat] Waiting for authentication message...")
            auth_data = await asyncio.wait_for(websocket.receive_json(), timeout=10.0)
            print(f"[WebChat] Received auth data: {auth_data}")
            
            user_id = auth_data.get("user_id", f"guest_{uuid.uuid4().hex[:8]}")
            user_name = auth_data.get("user_name", "Guest User")
            print(f"[WebChat] Authenticated user: {user_id} ({user_name})")
        except asyncio.TimeoutError:
            print("[WebChat] Authentication timeout, using guest credentials")
            user_id = f"guest_{uuid.uuid4().hex[:8]}"
            user_name = "Guest User"
        except Exception as e:
            print(f"[WebChat] Authentication error: {e}, using guest credentials")
            user_id = f"guest_{uuid.uuid4().hex[:8]}"
            user_name = "Guest User"

        # Create connection
        connection = WebChatConnection(websocket, user_id, session_id)
        self.connections[session_id] = connection
        print(f"[WebChat] Connection created for session: {session_id}")

        # Create or get conversation
        if session_id not in self.conversations:
            self.conversations[session_id] = Conversation(
                id=session_id,
                platform="webchat",
                type="direct",
                name=f"Chat with {user_name}",
                metadata={"started_at": datetime.utcnow().isoformat()},
            )
            print(f"[WebChat] Conversation created for session: {session_id}")

        # Send welcome message
        await self._send_system_message(
            connection, "Welcome to MOJI Web Chat! How can I help you today?"
        )

        try:
            # Handle incoming messages with improved stability
            while True:
                try:
                    # WebSocket ë©”ì‹œì§€ ìˆ˜ì‹  (íƒ€ìž„ì•„ì›ƒ ì¶”ê°€)
                    data = await asyncio.wait_for(websocket.receive_json(), timeout=60.0)
                    
                    # Handle ping/pong messages
                    if data.get("type") == "ping":
                        await connection.send({"type": "pong", "timestamp": datetime.utcnow().isoformat()})
                        connection.last_activity = datetime.utcnow()
                        continue
                    elif data.get("type") == "pong":
                        # Update last activity for pong messages
                        connection.last_activity = datetime.utcnow()
                        continue
                    
                except asyncio.TimeoutError:
                    # íƒ€ìž„ì•„ì›ƒ ì‹œ ping ì „ì†¡ìœ¼ë¡œ ì—°ê²° í™•ì¸
                    try:
                        await connection.send({"type": "ping", "timestamp": datetime.utcnow().isoformat()})
                        continue
                    except Exception:
                        print("[WebChat] Connection timeout, closing...")
                        break
                except Exception as e:
                    print(f"[WebChat] WebSocket receive error: {e}")
                    break

                message = await self._process_incoming_message(data, connection)

                # Process message with LLM router
                if message.text and message.text.strip():
                    try:
                        # Check for RAG commands
                        if message.text.startswith("/rag "):
                            # Handle RAG queries
                            from app.rag.enhanced_rag import rag_pipeline

                            query = message.text[5:].strip()  # Remove "/rag " prefix
                            print(f"[WebChat] RAG query: {query}")

                            # Get answer with confidence
                            result = await rag_pipeline.answer_with_confidence(query)

                            # Format response
                            response_text = f"**ë‹µë³€**: {result['answer']}\n\n"
                            response_text += f"**ì‹ ë¢°ë„**: {result['confidence']}\n"
                            response_text += f"**ê·¼ê±°**: {result['reasoning']}\n"

                            if result["sources"]:
                                response_text += "\n**ì¶œì²˜**:\n"
                                for source in result["sources"]:
                                    response_text += f"- {source}\n"

                            await connection.send(
                                {
                                    "id": str(uuid.uuid4()),
                                    "type": "text",
                                    "text": response_text,
                                    "timestamp": datetime.utcnow().isoformat(),
                                }
                            )

                        elif message.text == "/rag-stats":
                            # Show RAG statistics
                            from app.rag.enhanced_rag import rag_pipeline

                            stats = rag_pipeline.get_collection_stats()
                            response_text = "**RAG ì‹œìŠ¤í…œ í†µê³„**\n"
                            response_text += (
                                f"- ì´ ë¬¸ì„œ ìˆ˜: {stats.get('total_documents', 0)}\n"
                            )
                            response_text += (
                                f"- ì²­í¬ í¬ê¸°: {stats.get('chunk_size', 0)}\n"
                            )
                            response_text += (
                                f"- ì²­í¬ ì˜¤ë²„ëž©: {stats.get('chunk_overlap', 0)}\n"
                            )
                            response_text += f"- ìž„ë² ë”© ëª¨ë¸: {stats.get('embedding_model', 'Unknown')}\n"

                            await connection.send(
                                {
                                    "id": str(uuid.uuid4()),
                                    "type": "text",
                                    "text": response_text,
                                    "timestamp": datetime.utcnow().isoformat(),
                                }
                            )

                        elif message.text == "/rag-help":
                            # Show RAG help
                            help_text = """**RAG ì‹œìŠ¤í…œ ì‚¬ìš©ë²•**

1. **ë¬¸ì„œ ì—…ë¡œë“œ**: APIë¥¼ í†µí•´ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”
   - ì§€ì› í˜•ì‹: .txt, .md, .docx

2. **ì§ˆë¬¸í•˜ê¸°**: `/rag [ì§ˆë¬¸]`
   ì˜ˆì‹œ: `/rag í”„ë¡œì íŠ¸ì˜ ì£¼ìš” ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?`

3. **í†µê³„ ë³´ê¸°**: `/rag-stats`
   í˜„ìž¬ ì €ìž¥ëœ ë¬¸ì„œ ìˆ˜ì™€ ì„¤ì •ì„ í™•ì¸í•©ë‹ˆë‹¤.

4. **ì¼ë°˜ ëŒ€í™”**: ì¼ë°˜ ë©”ì‹œì§€ëŠ” ChatGPTê°€ ë‹µë³€í•©ë‹ˆë‹¤.

**íŠ¹ì§•**:
- ì§ˆì˜ ìž¬ìž‘ì„±ìœ¼ë¡œ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
- ì‹ ë¢°ë„ ì ìˆ˜ ì œê³µ (HIGH/MEDIUM/LOW)
- ë‹µë³€ ê·¼ê±° ë° ì¶œì²˜ í‘œì‹œ"""

                            await connection.send(
                                {
                                    "id": str(uuid.uuid4()),
                                    "type": "text",
                                    "text": help_text,
                                    "timestamp": datetime.utcnow().isoformat(),
                                }
                            )

                        else:
                            # Initialize components on first use (lazy loading)
                            from app.rag.enhanced_rag import rag_pipeline
                            from app.llm.router import llm_router
                            from app.agents.manager import agent_manager

                            # Initialize LLM router if not already done
                            if not llm_router.current_provider:
                                await llm_router.initialize()

                            # Initialize agent system if not already done
                            if not agent_manager.agents:
                                await agent_manager.initialize_default_agents()

                            # Log incoming message
                            print(f"[WebChat] Received message: {message.text}")

                            # Check RAG setting from client
                            use_rag = data.get(
                                "useRag", True
                            )  # Default to True for backward compatibility
                            strict_rag_mode = data.get(
                                "strictRagMode", True
                            )  # ì—„ê²©í•œ RAG ëª¨ë“œ (ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ë§Œ)
                            provider = data.get("provider")
                            model = data.get("model")

                            print(
                                f"[WebChat] RAG setting: {use_rag}, Strict mode: {strict_rag_mode}, Provider: {provider}, Model: {model}"
                            )

                            try:
                                if use_rag:
                                    # Try Hybrid RAG first (improved search)
                                    print("[WebChat] Trying Hybrid RAG search...")
                                    from app.rag.enhanced_rag import get_hybrid_pipeline

                                    hybrid_pipeline = get_hybrid_pipeline()

                                    # RAG ê²€ìƒ‰ ìž„ê³„ê°’ì„ ì—„ê²© ëª¨ë“œì— ë”°ë¼ ì¡°ì •
                                    search_threshold = 0.3 if strict_rag_mode else 0.1

                                    # Contextì— strict mode ì •ë³´ í¬í•¨
                                    search_context = {
                                        "strict_mode": strict_rag_mode,
                                        "provider": provider,
                                        "model": model,
                                    }
                                    
                                    rag_result = await hybrid_pipeline.answer_with_hybrid_search(
                                        message.text,
                                        k=5,
                                        score_threshold=search_threshold,
                                        context=search_context,
                                    )

                                    # RAG ê²°ê³¼ íƒ€ìž… ì²´í¬ ì¶”ê°€
                                    if (
                                        rag_result
                                        and isinstance(rag_result, dict)  # íƒ€ìž… ì²´í¬ ì¶”ê°€
                                        and rag_result.get("sources")
                                        and len(rag_result.get("sources", [])) > 0
                                        and rag_result.get("answer")
                                        and "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                                        not in rag_result.get("answer", "")
                                    ):

                                        print("[WebChat] Using Hybrid RAG response")
                                        # Use Hybrid RAG response
                                        response_text = rag_result["answer"]

                                        # Enhanced metadata with hybrid search info
                                        sources = rag_result.get("sources", [])
                                        confidence = rag_result.get(
                                            "confidence", "MEDIUM"
                                        )
                                        search_metadata = rag_result.get(
                                            "search_metadata", {}
                                        )

                                        # sourcesê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                                        if not isinstance(sources, list):
                                            sources = []
                                            
                                        metadata = {
                                            "mode": "Hybrid-RAG",
                                            "confidence": confidence,
                                            "sources": len(sources),
                                            "search_type": search_metadata.get(
                                                "search_type", "hybrid"
                                            ),
                                            "total_results": search_metadata.get(
                                                "total_results", 0
                                            ),
                                        }
                                        
                                        # RAG í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì¶œì²˜ ì •ë³´ í‘œì‹œ
                                        search_info = f"ì‹ ë¢°ë„: {confidence}, ì¶œì²˜: {len(sources)}ê°œ"
                                        if search_metadata.get("total_results"):
                                            search_info += f", ê²€ìƒ‰ê²°ê³¼: {search_metadata['total_results']}ê°œ"
                                        
                                        # ì¶œì²˜ ë¬¸ì„œ ì´ë¦„ë“¤ ì¶”ê°€ (ì•ˆì „í•œ ì²˜ë¦¬)
                                        source_files = []
                                        for source in sources:
                                            if isinstance(source, dict):
                                                filename = source.get('filename', source.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ'))
                                                source_files.append(filename)
                                            elif isinstance(source, str):
                                                source_files.append(source)
                                            else:
                                                source_files.append('ì•Œ ìˆ˜ ì—†ìŒ')
                                        
                                        source_files = list(set(source_files))  # ì¤‘ë³µ ì œê±°
                                        source_files_str = ", ".join(source_files[:3])  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                                        if len(source_files) > 3:
                                            source_files_str += f" ì™¸ {len(source_files)-3}ê°œ"
                                        
                                        response_text += f"\n\nðŸ“Š **RAG ì •ë³´**: {search_info}\nðŸ“„ **ì¶œì²˜**: {source_files_str}"

                                        await connection.send(
                                            {
                                                "id": str(uuid.uuid4()),
                                                "type": "text",
                                                "text": response_text,
                                                "timestamp": datetime.utcnow().isoformat(),
                                                "metadata": metadata,
                                            }
                                        )
                                    else:
                                        # No relevant documents found
                                        if strict_rag_mode:
                                            # ì—„ê²© ëª¨ë“œ: LLM í´ë°± ì—†ì´ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ë§Œ ì œê³µ
                                            print(
                                                "[WebChat] No relevant documents found, strict mode - no LLM fallback"
                                            )
                                            await connection.send(
                                                {
                                                    "id": str(uuid.uuid4()),
                                                    "type": "text",
                                                    "text": "ì£„ì†¡í•©ë‹ˆë‹¤. ì—…ë¡œë“œëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œê±°ë‚˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.",
                                                    "timestamp": datetime.utcnow().isoformat(),
                                                    "metadata": {
                                                        "mode": "Strict-RAG",
                                                        "confidence": "LOW",
                                                        "sources": 0,
                                                        "message": "ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ë§Œ ì œê³µ (LLM í´ë°± ë¹„í™œì„±í™”)",
                                                    },
                                                }
                                            )
                                        else:
                                            # ì¼ë°˜ ëª¨ë“œ: LLM í´ë°± ì‚¬ìš©
                                            print(
                                                "[WebChat] No relevant documents found, using regular LLM"
                                            )
                                            await self._generate_llm_response(
                                                connection,
                                                message.text,
                                                provider,
                                                model,
                                                "Hybrid",
                                            )
                                else:
                                    # RAG disabled, use LLM directly
                                    print("[WebChat] RAG disabled, using LLM directly")
                                    await self._generate_llm_response(
                                        connection, message.text, provider, model, "LLM"
                                    )

                            except Exception as rag_error:
                                error_msg = str(rag_error)
                                print(f"[WebChat] RAG error: {error_msg}, falling back to LLM")
                                
                                # êµ¬ì²´ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ ì œê³µ
                                if "'NoneType' object has no attribute '_collection'" in error_msg:
                                    error_detail = "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                                elif "No documents found" in error_msg:
                                    error_detail = "ì—…ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. RAG ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë¬¸ì„œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                                elif "unexpected keyword argument" in error_msg:
                                    error_detail = "RAG ì‹œìŠ¤í…œ ì„¤ì • ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                                else:
                                    error_detail = f"RAG ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {error_msg}"
                                
                                print(f"[WebChat] Error detail: {error_detail}")
                                
                                # Fallback to LLM with error context
                                await self._generate_llm_response(
                                    connection,
                                    message.text,
                                    provider,
                                    model,
                                    f"RAG-ì˜¤ë¥˜-í´ë°± ({error_detail})",
                                )

                    except Exception as e:
                        print(f"[WebChat] Error processing message: {str(e)}")
                        import traceback

                        traceback.print_exc()
                        await self.handle_error(e)
                        # Send error message to client
                        await connection.send(
                            {
                                "id": str(uuid.uuid4()),
                                "type": "system",
                                "text": f"ì£„ì†¡í•©ë‹ˆë‹¤. ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                                "timestamp": datetime.utcnow().isoformat(),
                            }
                        )

        except WebSocketDisconnect:
            # Clean up connection
            if session_id in self.connections:
                del self.connections[session_id]
        except Exception as e:
            await self.handle_error(e)
            # Clean up connection
            if session_id in self.connections:
                del self.connections[session_id]
            # Try to close websocket safely
            try:
                if not websocket.client_state.DISCONNECTED:
                    await websocket.close(code=1000, reason="Server error")
            except Exception:
                # Ignore close errors (connection might already be closed)
                pass

    async def send_message(self, message: PlatformMessage) -> Dict[str, Any]:
        """Send message to WebChat client."""
        if not await self.validate_message(message):
            raise ValueError("Invalid message format")

        # Find target connection
        target_session = message.conversation.id if message.conversation else None
        if not target_session or target_session not in self.connections:
            return {
                "id": str(message.id),
                "status": "failed",
                "error": "Connection not found",
            }

        connection = self.connections[target_session]

        # Convert to WebChat format
        webchat_message = await self._convert_to_webchat_format(message)

        # Send through WebSocket
        await connection.send(webchat_message)

        return {
            "id": str(message.id),
            "status": "sent",
            "platform": "webchat",
            "timestamp": message.timestamp.isoformat(),
        }

    async def receive_message(self, raw_message: Dict[str, Any]) -> PlatformMessage:
        """Convert WebChat message to platform message."""
        msg = PlatformMessage(
            id=raw_message.get("id", str(uuid.uuid4())),
            type=MessageType(raw_message.get("type", "text")),
            text=raw_message.get("text"),
            timestamp=datetime.fromisoformat(
                raw_message.get("timestamp", datetime.utcnow().isoformat())
            ),
            platform_specific={"webchat_data": raw_message},
        )

        # Set user from raw message
        if raw_message.get("user"):
            msg.user = User(
                id=raw_message["user"]["id"],
                name=raw_message["user"]["name"],
                platform="webchat",
                avatar_url=raw_message["user"].get("avatar"),
            )

        # Set conversation
        if raw_message.get("session_id"):
            msg.conversation = self.conversations.get(raw_message["session_id"])

        # Process attachments
        if raw_message.get("attachments"):
            msg.attachments = [
                Attachment(
                    type=AttachmentType(att["type"]),
                    url=att.get("url"),
                    file_name=att.get("name"),
                    file_size=att.get("size"),
                    mime_type=att.get("mime_type"),
                )
                for att in raw_message["attachments"]
            ]

        return msg

    async def get_user_info(self, user_id: str) -> User:
        """Get WebChat user information."""
        # Find user in active connections
        for conn in self.connections.values():
            if conn.user_id == user_id:
                return User(
                    id=user_id,
                    name=f"User {user_id}",
                    platform="webchat",
                    metadata={
                        "session_id": conn.session_id,
                        "connected_at": conn.connected_at.isoformat(),
                    },
                )

        # Return default user info
        return User(
            id=user_id,
            name=f"User {user_id}",
            platform="webchat",
        )

    async def get_conversation_info(self, conversation_id: str) -> Conversation:
        """Get WebChat conversation information."""
        if conversation_id in self.conversations:
            return self.conversations[conversation_id]

        return Conversation(
            id=conversation_id,
            platform="webchat",
            type="direct",
        )

    async def broadcast_message(self, message: PlatformMessage) -> Dict[str, Any]:
        """Broadcast message to all connected clients."""
        webchat_message = await self._convert_to_webchat_format(message)

        # Send to all connections
        results = []
        for session_id, connection in self.connections.items():
            try:
                await connection.send(webchat_message)
                results.append(session_id)
            except Exception as e:
                await self.handle_error(e)

        return {
            "status": "broadcast",
            "recipients": len(results),
            "sessions": results,
        }

    async def _generate_llm_response(
        self,
        connection: WebChatConnection,
        text: str,
        provider: str = None,
        model: str = None,
        mode: str = "LLM",
    ) -> None:
        """Generate LLM response and send to client"""
        from app.llm.router import llm_router
        from langchain_core.messages import HumanMessage

        try:
            # Create messages list for LLM
            messages = [HumanMessage(content=text)]

            # Generate response with optional provider/model
            print(
                f"[WebChat] Generating LLM response with provider={provider}, model={model}..."
            )
            response = await llm_router.generate(
                messages=messages, provider=provider, model=model
            )
            print(f"[WebChat] Generated response: {response.content}")

            # Add mode indicator to response (ì œê±°ë¨)
            response_text = response.content
            # if mode == "LLM":
            #     response_text += f"\n\nðŸ¤– **LLM ì‘ë‹µ** ({provider or 'default'})"
            # elif mode == "Hybrid":
            #     response_text += "\n\nðŸ”„ **í•˜ì´ë¸Œë¦¬ë“œ ì‘ë‹µ** (RAG â†’ LLM í´ë°±)"
            # elif mode == "Error-Fallback":
            #     response_text += "\n\nâš ï¸ **ì˜¤ë¥˜ ë³µêµ¬** (LLM í´ë°±)"

            # Send response back to client
            await connection.send(
                {
                    "id": str(uuid.uuid4()),
                    "type": "text",
                    "text": response_text,
                    "timestamp": datetime.utcnow().isoformat(),
                    "metadata": {"mode": mode, "provider": provider, "model": model},
                }
            )

        except Exception as e:
            print(f"[WebChat] LLM generation error: {str(e)}")
            await connection.send(
                {
                    "id": str(uuid.uuid4()),
                    "type": "text",
                    "text": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                    "timestamp": datetime.utcnow().isoformat(),
                }
            )

    async def _process_incoming_message(
        self, data: Dict[str, Any], connection: WebChatConnection
    ) -> PlatformMessage:
        """Process incoming WebChat message."""
        # Add metadata
        data["user"] = {
            "id": connection.user_id,
            "name": f"User {connection.user_id}",
        }
        data["session_id"] = connection.session_id
        data["timestamp"] = datetime.utcnow().isoformat()

        return await self.receive_message(data)

    async def _convert_to_webchat_format(
        self, message: PlatformMessage
    ) -> Dict[str, Any]:
        """Convert platform message to WebChat format."""
        data = {
            "id": str(message.id),
            "type": message.type.value,
            "timestamp": message.timestamp.isoformat(),
        }

        if message.text:
            data["text"] = message.text

        if message.attachments:
            data["attachments"] = [
                {
                    "type": att.type.value,
                    "url": att.url,
                    "name": att.file_name,
                    "size": att.file_size,
                    "mime_type": att.mime_type,
                }
                for att in message.attachments
            ]

        if message.buttons:
            data["buttons"] = [
                {
                    "text": btn.text,
                    "value": btn.value,
                    "action": btn.action,
                }
                for btn in message.buttons
            ]

        if message.cards:
            data["cards"] = [
                {
                    "title": card.title,
                    "subtitle": card.subtitle,
                    "text": card.text,
                    "image": card.image_url,
                    "buttons": [
                        {"text": btn.text, "value": btn.value} for btn in card.buttons
                    ],
                }
                for card in message.cards
            ]

        return data

    async def _send_system_message(
        self, connection: WebChatConnection, text: str
    ) -> None:
        """Send system message to client."""
        await connection.send(
            {
                "id": str(uuid.uuid4()),
                "type": "system",
                "text": text,
                "timestamp": datetime.utcnow().isoformat(),
            }
        )

    async def _cleanup_inactive_connections(self) -> None:
        """Clean up inactive connections periodically."""
        while True:
            try:
                await asyncio.sleep(300)  # Check every 5 minutes

                now = datetime.utcnow()
                inactive_threshold = 3600  # 1 hour

                for session_id, conn in list(self.connections.items()):
                    if (now - conn.last_activity).total_seconds() > inactive_threshold:
                        await conn.websocket.close()
                        del self.connections[session_id]

            except asyncio.CancelledError:
                break
            except Exception as e:
                await self.handle_error(e)

    def get_widget_html(self, config: Optional[Dict[str, Any]] = None) -> str:
        """Generate HTML for embeddable widget."""
        widget_config = config or self.widget_config

        return f"""
        <!-- MOJI Web Chat Widget -->
        <div id="moji-webchat-widget"></div>
        <script src="{widget_config.get('script_url', '/static/moji-webchat.js')}"></script>
        <script>
          MojiWebChat.init({{
            apiUrl: '{widget_config.get('api_url', '/api/v1/webchat')}',
            theme: '{widget_config.get('theme', 'light')}',
            position: '{widget_config.get('position', 'bottom-right')}',
            title: '{widget_config.get('title', 'MOJI Assistant')}',
            placeholder: '{widget_config.get('placeholder', 'Type your message...')}',
          }});
        </script>
        """

    def supports_feature(self, feature: str) -> bool:
        """Check WebChat feature support."""
        features = {
            "buttons": True,
            "cards": True,
            "files": True,
            "images": True,
            "audio": True,
            "video": True,
            "location": False,
            "typing_indicator": True,
            "read_receipts": True,
            "reactions": False,
            "persistent_history": True,
            "file_upload": True,
        }
        return features.get(feature, False)
