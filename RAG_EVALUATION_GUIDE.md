# RAG í‰ê°€ ì‹œìŠ¤í…œ ì‚¬ìš© ê°€ì´ë“œ (v2.1)

MOJI AI Agentì˜ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ê°œì„ í•˜ê¸° ìœ„í•œ ì¢…í•© ê°€ì´ë“œì…ë‹ˆë‹¤.

**ìµœì‹  ì—…ë°ì´íŠ¸ (2025-01-07)**: ì²­í‚¹ í’ˆì§ˆ í‰ê°€, Vector DB ì„±ëŠ¥ í‰ê°€, ì¢…í•© í‰ê°€ ì‹œìŠ¤í…œ ì¶”ê°€

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ì„¤ì¹˜ ë° ì„¤ì •](#ì„¤ì¹˜-ë°-ì„¤ì •)
3. [ì£¼ìš” êµ¬ì„± ìš”ì†Œ](#ì£¼ìš”-êµ¬ì„±-ìš”ì†Œ)
4. [ì‚¬ìš©ë²•](#ì‚¬ìš©ë²•)
5. [í‰ê°€ ë©”íŠ¸ë¦­](#í‰ê°€-ë©”íŠ¸ë¦­)
6. [ì¢…í•© í‰ê°€ ì‹œìŠ¤í…œ](#ì¢…í•©-í‰ê°€-ì‹œìŠ¤í…œ)
7. [ê²°ê³¼ í•´ì„](#ê²°ê³¼-í•´ì„)
8. [ê°œì„  ë°©ì•ˆ](#ê°œì„ -ë°©ì•ˆ)
9. [ìµœì‹  RAG êµ¬ì„±](#ìµœì‹ -rag-êµ¬ì„±)
10. [ê³ ê¸‰ ì‚¬ìš©ë²•](#ê³ ê¸‰-ì‚¬ìš©ë²•)
11. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

## ğŸ¯ ê°œìš”

RAG í‰ê°€ ì‹œìŠ¤í…œì€ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:

- **ìë™í™”ëœ ì„±ëŠ¥ í‰ê°€**: RAGAS ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•œ ê°ê´€ì  ì„±ëŠ¥ ì¸¡ì •
- **ì²­í‚¹ í’ˆì§ˆ í‰ê°€**: ì˜ë¯¸ì  ì¼ê´€ì„±, ê²½ê³„ í’ˆì§ˆ, ì •ë³´ ì»¤ë²„ë¦¬ì§€ ë¶„ì„
- **Vector DB ì„±ëŠ¥ í‰ê°€**: ì¸ë±ìŠ¤ í’ˆì§ˆ, ê²€ìƒ‰ ì •í™•ë„, ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì¸¡ì •
- **ì‹œê°ì  ë¶„ì„**: ì°¨íŠ¸ì™€ ê·¸ë˜í”„ë¥¼ í†µí•œ ì§ê´€ì  ê²°ê³¼ í™•ì¸
- **ì¢…í•© ë¦¬í¬íŠ¸**: HTML ê¸°ë°˜ í†µí•© ëŒ€ì‹œë³´ë“œ
- **ê°œì„  ì¶”ì²œ**: AI ê¸°ë°˜ ì„±ëŠ¥ ê°œì„  ë°©ì•ˆ ì œì‹œ
- **ë°°ì¹˜ ì²˜ë¦¬**: ëŒ€ëŸ‰ ì¿¼ë¦¬ ë™ì‹œ í‰ê°€
- **ìºì‹± ì§€ì›**: íš¨ìœ¨ì ì¸ ì¬í‰ê°€

## ğŸ”§ ì„¤ì¹˜ ë° ì„¤ì •

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# ê¸°ë³¸ ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# RAGAS ì¶”ê°€ ì„¤ì¹˜ (ì„ íƒì‚¬í•­)
pip install ragas>=0.1.0

# ì˜ë¯¸ë¡ ì  ì²­í‚¹ìš© ì¶”ê°€ íŒ¨í‚¤ì§€
pip install nltk sentence-transformers

# ê°€ìƒí™˜ê²½ ì‚¬ìš© ê¶Œì¥
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ë˜ëŠ”
venv\Scripts\activate     # Windows
pip install -r requirements.txt
```

### 2. ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬

```bash
# ë²¡í„° ìŠ¤í† ì–´ë§Œ ì´ˆê¸°í™” (ë¬¸ì„œ ì¬ì¸ë±ì‹± ì—†ì´)
python3 clear_and_reload_docs.py --clear-only -y

# ì „ì²´ ì´ˆê¸°í™” ë° ì¬ì¸ë±ì‹±
python3 clear_and_reload_docs.py -y

# ChromaDBë§Œ ì´ˆê¸°í™” (FAISSëŠ” ìœ ì§€)
python3 clear_and_reload_docs.py --clear-only --no-faiss -y
```

### 3. ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸

```
agentmojichat/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ragas_evaluator.py
â”‚   â”‚   â””â”€â”€ metrics_dashboard.py
â”‚   â””â”€â”€ rag/
â”‚       â”œâ”€â”€ semantic_chunker.py    # NEW: ì˜ë¯¸ë¡ ì  ì²­í‚¹
â”‚       â”œâ”€â”€ enhanced_rag.py        # ì—…ë°ì´íŠ¸ë¨
â”‚       â””â”€â”€ hybrid_search.py       # ì—…ë°ì´íŠ¸ë¨
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/          # RAG ë¬¸ì„œë“¤
â”‚   â”œâ”€â”€ evaluation/         # í‰ê°€ ê²°ê³¼ ì €ì¥
â”‚   â””â”€â”€ demo_documents/     # ë°ëª¨ìš© ë¬¸ì„œ
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ evaluation_demo.py  # ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸ (í™•ì¥ë¨)
â”œâ”€â”€ rag_health_check.py     # ì—…ë°ì´íŠ¸ë¨
â”œâ”€â”€ upload_docs.py          # ì—…ë°ì´íŠ¸ë¨
â”œâ”€â”€ clear_and_reload_docs.py # ì—…ë°ì´íŠ¸ë¨
â””â”€â”€ vector_db_manager.py    # ì—…ë°ì´íŠ¸ë¨
```

### 4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env íŒŒì¼ì— ì¶”ê°€
LLM_PROVIDER=deepseek
LLM_API_KEY=your_api_key_here
OPENAI_API_KEY=your_openai_key_here  # ì„ë² ë”©ìš©
```

## ğŸ§© ì£¼ìš” êµ¬ì„± ìš”ì†Œ

### 1. RAGASEvaluator (`app/evaluation/ragas_evaluator.py`)

RAG ì‹œìŠ¤í…œì˜ í•µì‹¬ í‰ê°€ ì—”ì§„ì…ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
- RAGAS ë©”íŠ¸ë¦­ ê³„ì‚°
- í´ë°± ë©”íŠ¸ë¦­ ì œê³µ
- ë°°ì¹˜ í‰ê°€ ì§€ì›
- ê²°ê³¼ ìë™ ì €ì¥

### 2. MetricsDashboard (`app/evaluation/metrics_dashboard.py`)

í‰ê°€ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ê³  ë¶„ì„í•˜ëŠ” ëŒ€ì‹œë³´ë“œì…ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
- 6ê°€ì§€ ì‹œê°í™” ì°¨íŠ¸
- HTML ë¦¬í¬íŠ¸ ìƒì„±
- ì„±ëŠ¥ ë¶„ì„
- ê°œì„  ì¶”ì²œ ìƒì„±

### 3. ì²­í‚¹ í’ˆì§ˆ í‰ê°€ê¸° (`app/evaluation/chunk_quality_evaluator.py`)

**NEW**: ë¬¸ì„œ ì²­í‚¹ì˜ í’ˆì§ˆì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
- ì˜ë¯¸ì  ì¼ê´€ì„± ì¸¡ì •
- ì²­í¬ ê²½ê³„ í’ˆì§ˆ ë¶„ì„
- ì •ë³´ ì»¤ë²„ë¦¬ì§€ í‰ê°€
- êµ¬ì¡° ë³´ì¡´ ë¶„ì„
- í¬ê¸° ì¼ê´€ì„± ê²€ì¦

### 4. Vector DB ì„±ëŠ¥ í‰ê°€ê¸° (`app/evaluation/vectordb_performance_evaluator.py`)

**NEW**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ ì„±ëŠ¥ì„ ë‹¤ê°ë„ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
- ì¸ë±ìŠ¤ í’ˆì§ˆ ë¶„ì„
- ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í‰ê°€
- í™•ì¥ì„± í…ŒìŠ¤íŠ¸
- ì¼ê´€ì„± ê²€ì¦

### 5. í‰ê°€ ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸ (`scripts/evaluation_demo.py`)

**ì—…ë°ì´íŠ¸**: ì¢…í•© í‰ê°€ ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸš€ ì‚¬ìš©ë²•

### 1. ë¹ ë¥¸ ì‹œì‘ - ë°ëª¨ ì‹¤í–‰

```bash
# ì „ì²´ í‰ê°€ ë°ëª¨ ì‹¤í–‰
cd /home/smhaccp/dev/agentmojichat
python scripts/evaluation_demo.py

# ë‹¨ì¼ ì¿¼ë¦¬ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
python scripts/evaluation_demo.py quick
```

### 2. í”„ë¡œê·¸ë˜ë° ë°©ì‹ ì‚¬ìš©

#### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
import asyncio
from app.rag.enhanced_rag import rag_pipeline
from app.evaluation.ragas_evaluator import RAGASEvaluator
from app.evaluation.metrics_dashboard import MetricsDashboard

async def basic_evaluation():
    # 1. í‰ê°€ê¸° ì´ˆê¸°í™”
    evaluator = RAGASEvaluator(
        rag_pipeline=rag_pipeline,
        use_ragas=True
    )
    
    # 2. ë‹¨ì¼ ì¿¼ë¦¬ í‰ê°€
    result = await evaluator.evaluate_single_query(
        query="íšŒì‚¬ì˜ ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
        ground_truth="Python, FastAPI, LangChain"  # ì„ íƒì‚¬í•­
    )
    
    print(f"ì‹ ë¢°ë„: {result.faithfulness:.3f}")
    print(f"ë‹µë³€ ê´€ë ¨ì„±: {result.answer_relevancy:.3f}")
    
    return result

# ì‹¤í–‰
asyncio.run(basic_evaluation())
```

#### ë°°ì¹˜ í‰ê°€

```python
async def batch_evaluation():
    evaluator = RAGASEvaluator(rag_pipeline=rag_pipeline)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    queries = [
        "íšŒì‚¬ ì´ë¦„ì´ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì§ì› ë³µë¦¬í›„ìƒì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
    ]
    
    # ë°°ì¹˜ í‰ê°€ ì‹¤í–‰
    results, summary = await evaluator.evaluate_dataset(
        queries=queries,
        save_results=True
    )
    
    # ëŒ€ì‹œë³´ë“œ ìƒì„±
    dashboard = MetricsDashboard()
    report = dashboard.generate_report(results, summary, save_plots=True)
    html_path = dashboard.create_html_report(results, summary)
    
    print(f"HTML ë¦¬í¬íŠ¸: {html_path}")
    return results, summary, report

# ì‹¤í–‰
asyncio.run(batch_evaluation())
```

### 3. ì»¤ìŠ¤í…€ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‚¬ìš©

```python
# ìì‹ ë§Œì˜ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì •ì˜
custom_queries = [
    "ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ì„¤ì¹˜ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
    "API ì‚¬ìš©ë²•ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
    "ë¬¸ì œ í•´ê²° ë°©ë²•ì€?"
]

# Ground truth ë‹µë³€ (ì„ íƒì‚¬í•­)
ground_truths = [
    "Python 3.11+, FastAPI, PostgreSQL í•„ìš”",
    "pip install í›„ docker-compose up",
    "REST API ì—”ë“œí¬ì¸íŠ¸ /api/v1/ ì‚¬ìš©",
    "ë¡œê·¸ í™•ì¸ í›„ ì´ìŠˆ íŠ¸ë˜ì»¤ ë“±ë¡"
]

# í‰ê°€ ì‹¤í–‰
results, summary = await evaluator.evaluate_dataset(
    queries=custom_queries,
    ground_truths=ground_truths
)
```

### 3. ì¢…í•© í‰ê°€ ì‹¤í–‰ (NEW)

```bash
# ì²­í‚¹ í’ˆì§ˆ + Vector DB ì„±ëŠ¥ + RAGAS ì¢…í•© í‰ê°€
python scripts/evaluation_demo.py comprehensive
```

### 4. í”„ë¡œê·¸ë˜ë° ë°©ì‹ ì‚¬ìš©

#### ì²­í‚¹ í’ˆì§ˆ í‰ê°€

```python
from app.evaluation.chunk_quality_evaluator import ChunkQualityEvaluator
from langchain.schema import Document

async def evaluate_chunk_quality():
    # í‰ê°€ê¸° ì´ˆê¸°í™”
    evaluator = ChunkQualityEvaluator(
        embedding_model="all-MiniLM-L6-v2",
        optimal_chunk_size=1000,
        size_tolerance=0.3
    )
    
    # ì²­í¬ ë¬¸ì„œë“¤ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê°€ì ¸ì˜´)
    chunks = [
        Document(page_content="ì²« ë²ˆì§¸ ì²­í¬ ë‚´ìš©...", metadata={"chunk_id": "1"}),
        Document(page_content="ë‘ ë²ˆì§¸ ì²­í¬ ë‚´ìš©...", metadata={"chunk_id": "2"}),
        # ... ë” ë§ì€ ì²­í¬ë“¤
    ]
    
    # ì›ë³¸ í…ìŠ¤íŠ¸
    original_text = "ì „ì²´ ì›ë³¸ ë¬¸ì„œ ë‚´ìš©..."
    
    # í’ˆì§ˆ í‰ê°€ ì‹¤í–‰
    metrics = evaluator.evaluate_chunks(chunks, original_text)
    
    print(f"ì¢…í•© í’ˆì§ˆ ì ìˆ˜: {metrics.overall_quality:.3f}")
    print(f"ì˜ë¯¸ì  ì¼ê´€ì„±: {metrics.semantic_coherence:.3f}")
    print(f"ê²½ê³„ í’ˆì§ˆ: {metrics.boundary_quality:.3f}")
    print(f"ì •ë³´ ì»¤ë²„ë¦¬ì§€: {metrics.information_coverage:.3f}")
    
    # ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±
    report = evaluator.generate_quality_report(metrics, chunks)
    print(f"í’ˆì§ˆ ë“±ê¸‰: {report['summary']['quality_grade']}")
    
    return metrics, report
```

#### Vector DB ì„±ëŠ¥ í‰ê°€

```python
from app.evaluation.vectordb_performance_evaluator import VectorDBPerformanceEvaluator
from app.rag.enhanced_rag import rag_pipeline

async def evaluate_vectordb_performance():
    # í‰ê°€ê¸° ì´ˆê¸°í™”
    evaluator = VectorDBPerformanceEvaluator(
        vectorstore=rag_pipeline.vectorstore,
        test_queries=[
            "ì‹œìŠ¤í…œ ì„¤ì¹˜ ë°©ë²•",
            "API ì‚¬ìš©ë²•",
            "ì—ëŸ¬ í•´ê²° ë°©ë²•",
            "ì„±ëŠ¥ ìµœì í™”"
        ],
        k_values=[1, 3, 5, 10]
    )
    
    # ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰
    metrics = evaluator.evaluate_performance(detailed_analysis=True)
    
    print(f"ì¢…í•© ì„±ëŠ¥ ì ìˆ˜: {metrics.overall_performance:.3f}")
    print(f"ì¸ë±ìŠ¤ í’ˆì§ˆ: {metrics.index_quality:.3f}")
    print(f"ê²€ìƒ‰ ì •í™•ë„: {metrics.search_accuracy:.3f}")
    print(f"ê²€ìƒ‰ ì†ë„: {metrics.search_speed:.3f}")
    print(f"ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: {metrics.memory_efficiency:.3f}")
    
    # ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±
    report = evaluator.generate_performance_report(metrics)
    print(f"ì„±ëŠ¥ ë“±ê¸‰: {report['summary']['performance_grade']}")
    
    return metrics, report
```

#### ì¢…í•© í‰ê°€ (í†µí•©)

```python
async def comprehensive_evaluation():
    """ì²­í‚¹ í’ˆì§ˆ + Vector DB ì„±ëŠ¥ + RAGAS ì¢…í•© í‰ê°€"""
    
    # 1. ì²­í‚¹ í’ˆì§ˆ í‰ê°€
    chunk_evaluator = ChunkQualityEvaluator()
    chunk_metrics = chunk_evaluator.evaluate_chunks(chunks, original_text)
    
    # 2. Vector DB ì„±ëŠ¥ í‰ê°€  
    vectordb_evaluator = VectorDBPerformanceEvaluator(
        vectorstore=rag_pipeline.vectorstore
    )
    vectordb_metrics = vectordb_evaluator.evaluate_performance()
    
    # 3. RAGAS í‰ê°€
    ragas_evaluator = RAGASEvaluator(rag_pipeline=rag_pipeline)
    results, summary = await ragas_evaluator.evaluate_dataset(queries)
    
    # 4. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    dashboard = MetricsDashboard()
    enhanced_report = {
        "chunk_quality": {
            "metrics": chunk_metrics.to_dict(),
            "grade": "Excellent"  # ì‹¤ì œë¡œëŠ” ê³„ì‚°ë¨
        },
        "vectordb_performance": {
            "metrics": vectordb_metrics.to_dict(), 
            "grade": "Good"  # ì‹¤ì œë¡œëŠ” ê³„ì‚°ë¨
        }
    }
    
    # ì¢…í•© HTML ë¦¬í¬íŠ¸ ìƒì„±
    html_path = dashboard.create_comprehensive_html_report(
        results, summary, enhanced_report
    )
    
    print(f"ì¢…í•© ë¦¬í¬íŠ¸: {html_path}")
    return enhanced_report
```

## ğŸ“Š í‰ê°€ ë©”íŠ¸ë¦­

### RAGAS ë©”íŠ¸ë¦­

| ë©”íŠ¸ë¦­ | ì„¤ëª… | ë²”ìœ„ | í•´ì„ |
|--------|------|------|------|
| **Faithfulness** | ë‹µë³€ì´ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì— ì–¼ë§ˆë‚˜ ì¶©ì‹¤í•œê°€ | 0.0-1.0 | ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ |
| **Answer Relevancy** | ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ìˆëŠ”ê°€ | 0.0-1.0 | ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ |
| **Context Precision** | ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì˜ ì •ë°€ë„ | 0.0-1.0 | ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ |
| **Context Recall** | ê´€ë ¨ ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ê²€ìƒ‰í–ˆëŠ”ê°€ | 0.0-1.0 | ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ |
| **Context Relevancy** | ì»¨í…ìŠ¤íŠ¸ê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ìˆëŠ”ê°€ | 0.0-1.0 | ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ |

### í´ë°± ë©”íŠ¸ë¦­

RAGAS ì„¤ì¹˜ê°€ ì•ˆ ëœ ê²½ìš° ì‚¬ìš©ë˜ëŠ” ëŒ€ì²´ ë©”íŠ¸ë¦­:
- í‚¤ì›Œë“œ ê¸°ë°˜ ê´€ë ¨ì„± ê³„ì‚°
- ë‹µë³€ ê¸¸ì´ ê¸°ë°˜ í’ˆì§ˆ í‰ê°€
- ì»¨í…ìŠ¤íŠ¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸

### ì„±ëŠ¥ ë©”íŠ¸ë¦­

- **Response Time**: ì‘ë‹µ ì‹œê°„ (ì´ˆ)
- **Retrieval Time**: ë¬¸ì„œ ê²€ìƒ‰ ì‹œê°„
- **Generation Time**: ë‹µë³€ ìƒì„± ì‹œê°„
- **Total Tokens**: ì‚¬ìš©ëœ í† í° ìˆ˜

## ğŸ“ˆ ê²°ê³¼ í•´ì„

### í’ˆì§ˆ ë“±ê¸‰

| í‰ê·  ì ìˆ˜ | ë“±ê¸‰ | ìƒíƒœ |
|-----------|------|------|
| 0.8+ | Excellent | ğŸŸ¢ ë§¤ìš° ì¢‹ìŒ |
| 0.6-0.8 | Good | ğŸŸ¡ ì¢‹ìŒ |
| 0.4-0.6 | Fair | ğŸŸ  ë³´í†µ |
| <0.4 | Poor | ğŸ”´ ê°œì„  í•„ìš” |

### ì£¼ìš” ì§€í‘œ í•´ì„

1. **Faithfulness < 0.7**: ë‹µë³€ì´ ë¬¸ì„œ ë‚´ìš©ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ
2. **Answer Relevancy < 0.6**: ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ë‚®ìŒ
3. **Context Precision < 0.5**: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì´ ë¶€ì •í™•í•¨
4. **Response Time > 3ì´ˆ**: ì‘ë‹µ ì†ë„ê°€ ëŠë¦¼ (í’ˆì§ˆ ìš°ì„  ì„¤ì •ì—ì„œëŠ” í—ˆìš© ë²”ìœ„)

### ìƒì„±ë˜ëŠ” íŒŒì¼ë“¤

```
data/evaluation/
â”œâ”€â”€ evaluation_results_YYYYMMDD_HHMMSS.json    # ìƒì„¸ ê²°ê³¼
â”œâ”€â”€ evaluation_results_YYYYMMDD_HHMMSS.csv     # CSV í˜•íƒœ ê²°ê³¼
â”œâ”€â”€ evaluation_summary_YYYYMMDD_HHMMSS.json    # ìš”ì•½ í†µê³„
â”œâ”€â”€ evaluation_report_YYYYMMDD_HHMMSS.html     # HTML ë¦¬í¬íŠ¸
â”œâ”€â”€ metrics_overview_YYYYMMDD_HHMMSS.png       # ê°œìš” ì°¨íŠ¸
â”œâ”€â”€ detailed_analysis_YYYYMMDD_HHMMSS.png      # ìƒì„¸ ë¶„ì„ ì°¨íŠ¸
â””â”€â”€ rag_report_YYYYMMDD_HHMMSS.json           # ì¢…í•© ë¦¬í¬íŠ¸
```

## ğŸ”§ ê°œì„  ë°©ì•ˆ

### ìë™ ì¶”ì²œ ì‹œìŠ¤í…œ

í‰ê°€ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒê³¼ ê°™ì€ ê°œì„  ë°©ì•ˆì´ ìë™ìœ¼ë¡œ ì œì•ˆë©ë‹ˆë‹¤:

1. **ì‹ ë¢°ë„ ê°œì„ **
   - ë” ì •í™•í•œ ë¬¸ì„œ ì²­í‚¹
   - ì»¨í…ìŠ¤íŠ¸ í•„í„°ë§ ê°•í™”
   - ê²€ìƒ‰ ì„ê³„ê°’ ì¡°ì •

2. **ê´€ë ¨ì„± ê°œì„ **
   - ì¿¼ë¦¬ ì¬ì‘ì„± í™œìš©
   - ë” ë‚˜ì€ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
   - ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ê°•í™”

3. **ì„±ëŠ¥ ê°œì„ **
   - ìºì‹± ì‹œìŠ¤í…œ í™œìš©
   - ë” ë¹ ë¥¸ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
   - ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”

4. **ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ê°œì„ **
   - ë¦¬ë­í‚¹ ì‹œìŠ¤í…œ ë„ì…
   - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš©
   - ë¬¸ì„œ í’ˆì§ˆ ê°œì„ 

### ìˆ˜ë™ ê°œì„  ì‘ì—…

1. **ë¬¸ì„œ ê°œì„ **
   ```bash
   # ë¬¸ì„œ í’ˆì§ˆ í™•ì¸
   python scripts/document_analyzer.py
   
   # ì¤‘ë³µ ë¬¸ì„œ ì œê±°
   python scripts/deduplicate_docs.py
   ```

2. **ê²€ìƒ‰ ì„¤ì • ì¡°ì •**
   ```python
   # hybrid_search.pyì—ì„œ ì„¤ì • ìˆ˜ì •
   vector_weight=0.4,      # ë²¡í„° ê²€ìƒ‰ ê°€ì¤‘ì¹˜
   keyword_weight=0.4,     # í‚¤ì›Œë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (ì¦ê°€)
   score_threshold=0.05,   # ë” ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ recall í–¥ìƒ
   ```

3. **ì²­í‚¹ ì „ëµ ë³€ê²½ (ìµœì‹  ê¶Œì¥ ì„¤ì •)**
   ```python
   # enhanced_rag.pyì—ì„œ ìµœì‹  ì„¤ì • ì‚¬ìš©
   use_semantic_chunking=True,  # ì˜ë¯¸ë¡ ì  ì²­í‚¹ í™œì„±í™”
   chunk_size=1500,            # í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ í° ì²­í¬
   chunk_overlap=500           # ê²½ê³„ ì •ë³´ ë³´ì¡´ ê°•í™”
   ```

## ğŸ†• ìµœì‹  RAG êµ¬ì„±

### í’ˆì§ˆ ì¤‘ì‹¬ ìµœì í™” (2025-07-07 ì—…ë°ì´íŠ¸)

ìµœì‹  RAG ì‹œìŠ¤í…œì€ ì‘ë‹µ ì†ë„ë³´ë‹¤ ë‹µë³€ í’ˆì§ˆì„ ìš°ì„ ì‹œí•˜ë„ë¡ ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤.

#### ì£¼ìš” ë³€ê²½ì‚¬í•­

1. **ì²­í‚¹ íŒŒë¼ë¯¸í„° í–¥ìƒ**
   ```python
   # ê¸°ì¡´ ì„¤ì •
   chunk_size=1000
   chunk_overlap=200
   
   # ìƒˆë¡œìš´ ì„¤ì • (í’ˆì§ˆ í–¥ìƒ)
   chunk_size=1500      # ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸ í¬í•¨
   chunk_overlap=500    # ê²½ê³„ ì •ë³´ ë³´ì¡´ ê°•í™”
   ```

2. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ ì¡°ì •**
   ```python
   # ê¸°ì¡´ ê°€ì¤‘ì¹˜
   vector_weight=0.5
   keyword_weight=0.3
   bm25_weight=0.2
   
   # ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ (í‚¤ì›Œë“œ ê²€ìƒ‰ ê°•í™”)
   vector_weight=0.4
   keyword_weight=0.4   # í‚¤ì›Œë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ ì¦ê°€
   bm25_weight=0.2
   ```

3. **ì˜ë¯¸ë¡ ì  ì²­í‚¹ í™œì„±í™”**
   ```python
   use_semantic_chunking=True  # ê¸°ë³¸ê°’ìœ¼ë¡œ í™œì„±í™”
   ```

4. **í–¥ìƒëœ ì¿¼ë¦¬ ì²˜ë¦¬**
   - ë„ë©”ì¸ë³„ í‚¤ì›Œë“œ ë³€í˜• ì‚¬ì „ ì¶”ê°€
   - Chain-of-Thought í•œêµ­ì–´ ì¶”ë¡  ì²´ì¸ ë„ì…
   - ë” ì •êµí•œ ì¿¼ë¦¬ ì¬ì‘ì„± ë¡œì§

#### ì„±ëŠ¥ ì„ê³„ê°’ ì¡°ì •

```python
# í’ˆì§ˆ ìš°ì„  í‰ê°€ ê¸°ì¤€
PERFORMANCE_THRESHOLDS = {
    "response_time": 3.0,        # ê¸°ì¡´ 2.0ì´ˆ â†’ 3.0ì´ˆ
    "faithfulness": 0.8,         # ì‹ ë¢°ë„ ì„ê³„ê°’ ìƒí–¥
    "answer_relevancy": 0.7,     # ê´€ë ¨ì„± ì„ê³„ê°’ ìƒí–¥
    "context_precision": 0.6     # ì •ë°€ë„ ì„ê³„ê°’ ìƒí–¥
}
```

### ì—…ë°ì´íŠ¸ëœ ìœ í‹¸ë¦¬í‹° ë„êµ¬ë“¤

#### 1. RAG ìƒíƒœ ì ê²€ (`rag_health_check.py`)
```bash
# ìƒˆë¡œìš´ ì ê²€ í•­ëª©ë“¤
python /tools/rag_health_check.py

# í™•ì¸ ì‚¬í•­:
# - ì˜ë¯¸ë¡ ì  ì²­í‚¹ ìƒíƒœ
# - ì—…ë°ì´íŠ¸ëœ ì²­í¬ íŒŒë¼ë¯¸í„°
# - ìƒˆë¡œìš´ ì„±ëŠ¥ ì„ê³„ê°’ (3ì´ˆ)
# - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
```

#### 2. ë¬¸ì„œ ì—…ë¡œë“œ ë„êµ¬ (`upload_docs.py`)
```bash
python /tools/upload_docs.py

# ìƒˆë¡œìš´ í†µê³„ í‘œì‹œ:
# - ì²­í¬ ì¤‘ë³µ ì •ë³´
# - ì˜ë¯¸ë¡ ì  ì²­í‚¹ ìƒíƒœ
# - í–¥ìƒëœ RAG ëª…ë ¹ì–´ ì˜ˆì‹œ
```

#### 3. ë²¡í„° DB ê´€ë¦¬ì (`vector_db_manager.py`)
```bash
python /tools/vector_db_manager.py stats

# í•œê¸€í™”ëœ í†µê³„ í‘œì‹œ:
# - ì´ ë¬¸ì„œ ìˆ˜: XXê°œ
# - ì²­í¬ í¬ê¸°: 1500
# - ì²­í¬ ì¤‘ë³µ: 500
# - ì˜ë¯¸ë¡ ì  ì²­í‚¹: í™œì„±í™”
```

### í‰ê°€ ì‹œ ê³ ë ¤ì‚¬í•­

1. **ì‘ë‹µ ì‹œê°„ í‰ê°€**
   - 3ì´ˆ ì´ë‚´: ìš°ìˆ˜
   - 3-5ì´ˆ: ì–‘í˜¸ (í’ˆì§ˆ ìš°ì„ )
   - 5ì´ˆ ì´ìƒ: ê°œì„  í•„ìš”

2. **í’ˆì§ˆ ì§€í‘œ ìš°ì„ ìˆœìœ„**
   ```
   1ìˆœìœ„: Faithfulness (ì‹ ë¢°ë„)
   2ìˆœìœ„: Answer Relevancy (ë‹µë³€ ê´€ë ¨ì„±)
   3ìˆœìœ„: Context Precision (ì»¨í…ìŠ¤íŠ¸ ì •ë°€ë„)
   4ìˆœìœ„: Response Time (ì‘ë‹µ ì‹œê°„)
   ```

3. **ì˜ë¯¸ë¡ ì  ì²­í‚¹ í‰ê°€**
   ```python
   # ì˜ë¯¸ë¡ ì  ì²­í‚¹ í™œì„±í™” í™•ì¸
   if stats.get('use_semantic_chunking'):
       # ë” ë†’ì€ í’ˆì§ˆ ê¸°ì¤€ ì ìš©
       quality_threshold = 0.8
   else:
       # í‘œì¤€ í’ˆì§ˆ ê¸°ì¤€
       quality_threshold = 0.7
   ```

### ì„¤ì • ê²€ì¦ ëª…ë ¹ì–´

```bash
# í˜„ì¬ RAG ì„¤ì • í™•ì¸
python rag_health_check.py

# ì˜ë¯¸ë¡ ì  ì²­í‚¹ ìƒíƒœ í™•ì¸
python upload_docs.py --no-test

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
python scripts/evaluation_demo.py quick
```

## ğŸ”¬ ê³ ê¸‰ ì‚¬ìš©ë²•

### 1. ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬

```bash
# ë²¡í„° ìŠ¤í† ì–´ ìƒíƒœ í™•ì¸
python3 clear_and_reload_docs.py --clear-only --help

# ì„ íƒì  ì´ˆê¸°í™” ì˜µì…˜ë“¤
python3 clear_and_reload_docs.py --clear-only              # í™•ì¸ í›„ ì´ˆê¸°í™”
python3 clear_and_reload_docs.py --clear-only -y           # ì¦‰ì‹œ ì´ˆê¸°í™”
python3 clear_and_reload_docs.py --clear-only --no-faiss   # ChromaDBë§Œ ì´ˆê¸°í™”
python3 clear_and_reload_docs.py --clear-only --no-faiss -y # ChromaDBë§Œ ì¦‰ì‹œ ì´ˆê¸°í™”
```

**ì£¼ìš” ì˜µì…˜ë“¤:**
- `--clear-only`: ë²¡í„° ìŠ¤í† ì–´ë§Œ ì‚­ì œí•˜ê³  ë¬¸ì„œ ì¬ì¸ë±ì‹±ì€ ê±´ë„ˆë›°ê¸°
- `-y, --yes`: í™•ì¸ í”„ë¡¬í”„íŠ¸ ì—†ì´ ìë™ìœ¼ë¡œ ì§„í–‰
- `--no-faiss`: FAISS ì¸ë±ìŠ¤ëŠ” ìœ ì§€í•˜ê³  ChromaDBë§Œ ì´ˆê¸°í™”

### 2. ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì¶”ê°€

```python
def custom_metric(result: EvaluationResult) -> float:
    """ì»¤ìŠ¤í…€ í‰ê°€ ë©”íŠ¸ë¦­"""
    # ë‹µë³€ ê¸¸ì´ì™€ í’ˆì§ˆì˜ ê· í˜• ì ìˆ˜
    length_score = min(len(result.answer) / 200, 1.0)
    quality_score = (result.faithfulness + result.answer_relevancy) / 2
    return (length_score + quality_score) / 2

# í‰ê°€ ê²°ê³¼ì— ì¶”ê°€
for result in results:
    result.custom_score = custom_metric(result)
```

### 3. A/B í…ŒìŠ¤íŠ¸

```python
async def ab_test_chunking_strategies():
    """ì²­í‚¹ ì „ëµ A/B í…ŒìŠ¤íŠ¸"""
    
    # ì „ëµ A: ê¸°ì¡´ ì„¤ì •
    pipeline_a = EnhancedRAGPipeline(
        use_semantic_chunking=False,
        chunk_size=1000,
        chunk_overlap=200
    )
    
    # ì „ëµ B: ìµœì‹  í’ˆì§ˆ ì¤‘ì‹¬ ì„¤ì •
    pipeline_b = EnhancedRAGPipeline(
        use_semantic_chunking=True,
        chunk_size=1500,
        chunk_overlap=500
    )
    
    test_queries = ["í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬1", "í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬2"]
    
    # ê° ì „ëµ í‰ê°€
    evaluator_a = RAGASEvaluator(pipeline_a)
    evaluator_b = RAGASEvaluator(pipeline_b)
    
    results_a, summary_a = await evaluator_a.evaluate_dataset(test_queries)
    results_b, summary_b = await evaluator_b.evaluate_dataset(test_queries)
    
    # ê²°ê³¼ ë¹„êµ
    print(f"ì „ëµ A í‰ê·  ì ìˆ˜: {summary_a.avg_faithfulness:.3f}")
    print(f"ì „ëµ B í‰ê·  ì ìˆ˜: {summary_b.avg_faithfulness:.3f}")
```

### 4. ì—°ì† ëª¨ë‹ˆí„°ë§

```python
import schedule
import time

def scheduled_evaluation():
    """ì •ê¸°ì  í‰ê°€ ì‹¤í–‰"""
    asyncio.run(batch_evaluation())
    
# ë§¤ì¼ ìì •ì— í‰ê°€ ì‹¤í–‰
schedule.every().day.at("00:00").do(scheduled_evaluation)

while True:
    schedule.run_pending()
    time.sleep(60)
```

## ğŸ” ë¬¸ì œ í•´ê²°

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤

1. **RAGAS ì„¤ì¹˜ ì‹¤íŒ¨**
   ```bash
   # í•´ê²°: í´ë°± ë©”íŠ¸ë¦­ ìë™ ì‚¬ìš©
   # ë˜ëŠ” ìˆ˜ë™ ì„¤ì¹˜
   pip install ragas datasets evaluate
   ```

2. **ë©”ëª¨ë¦¬ ë¶€ì¡±**
   ```python
   # ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
   evaluator = RAGASEvaluator(batch_size=5)
   ```

3. **ëŠë¦° í‰ê°€ ì†ë„**
   ```python
   # ë³‘ë ¬ ì²˜ë¦¬ ë¹„í™œì„±í™”
   use_parallel_search=False
   
   # ìºì‹± í™œìš©
   use_ragas=False  # í´ë°± ë©”íŠ¸ë¦­ ì‚¬ìš©
   ```

4. **ê¶Œí•œ ì˜¤ë¥˜**
   ```bash
   # ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸
   chmod 755 data/evaluation/
   ```

### ë¡œê·¸ í™•ì¸

```bash
# í‰ê°€ ë¡œê·¸ í™•ì¸
tail -f logs/evaluation.log

# ì˜¤ë¥˜ ë¡œê·¸ë§Œ í™•ì¸
grep ERROR logs/evaluation.log
```

### ì„±ëŠ¥ ìµœì í™”

1. **ìºì‹± í™œìš©**: ë™ì¼ ì¿¼ë¦¬ ì¬í‰ê°€ ë°©ì§€
2. **ë°°ì¹˜ í¬ê¸° ì¡°ì •**: ë©”ëª¨ë¦¬ì™€ ì†ë„ì˜ ê· í˜•
3. **ë³‘ë ¬ ì²˜ë¦¬**: CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì •
4. **ì„ë² ë”© ìºì‹±**: ë™ì¼ ë¬¸ì„œ ì¬ì²˜ë¦¬ ë°©ì§€

## ğŸ“š ì¶”ê°€ ìë£Œ

- [RAGAS ê³µì‹ ë¬¸ì„œ](https://docs.ragas.io/)
- [LangChain í‰ê°€ ê°€ì´ë“œ](https://python.langchain.com/docs/guides/evaluation/)
- [RAG ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ](./RAG_OPTIMIZATION_GUIDE.md)

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

í‰ê°€ ì‹œìŠ¤í…œ ê°œì„ ì— ê¸°ì—¬í•˜ê³  ì‹¶ë‹¤ë©´:

1. ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ ì œì•ˆ
2. ì‹œê°í™” ê°œì„ 
3. ì„±ëŠ¥ ìµœì í™”
4. ë¬¸ì„œ ê°œì„ 

ë¬¸ì˜ì‚¬í•­ì´ë‚˜ ë²„ê·¸ ë¦¬í¬íŠ¸ëŠ” ì´ìŠˆ íŠ¸ë˜ì»¤ì— ë“±ë¡í•´ ì£¼ì„¸ìš”.

---

*ì´ ê°€ì´ë“œëŠ” MOJI AI Agent RAG í‰ê°€ ì‹œìŠ¤í…œ v2.1ì„ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. (í’ˆì§ˆ ì¤‘ì‹¬ ìµœì í™” ë°˜ì˜)*