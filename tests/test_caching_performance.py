#!/usr/bin/env python3
"""
ìºì‹± ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
ìºì‹œ ì ìš© ì „í›„ ì„±ëŠ¥ ë¹„êµ ë° ìºì‹œ íš¨ìœ¨ì„± ì¸¡ì •
"""

import asyncio
import os
import sys
import time
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))


async def test_caching_performance():
    """ìºì‹± ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ìºì‹± ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # í™˜ê²½ ì„¤ì •
        from app.core.config import settings
        if settings.openai_api_key:
            os.environ['OPENAI_API_KEY'] = settings.openai_api_key
        elif settings.llm_api_key:
            os.environ['OPENAI_API_KEY'] = settings.llm_api_key
        
        from app.rag.enhanced_rag import rag_pipeline, get_hybrid_pipeline
        from app.core.cache import get_cache_stats, clear_cache
        
        # ìºì‹œ ì´ˆê¸°í™”
        await clear_cache()
        print("âœ… ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        hybrid_pipeline = get_hybrid_pipeline()
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤ (ë°˜ë³µ í…ŒìŠ¤íŠ¸ìš©)
        test_queries = [
            "MOJI AI ì—ì´ì „íŠ¸ì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "SMHACCP íšŒì‚¬ ì†Œê°œ ë° ì‚¬ì—… ë¶„ì•¼",
            "í”„ë¡œì íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ì¥ì ",
            "ì‹í’ˆì œì¡°ì—… AI ì†”ë£¨ì…˜",
            "ì‚¬ìš©ì ê´€ë¦¬ ê¸°ëŠ¥"
        ]
        
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¤ì •:")
        print(f"  - í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {len(test_queries)}ê°œ")
        print(f"  - ê° ì¿¼ë¦¬ 2íšŒ ì‹¤í–‰ (ì²« ë²ˆì§¸: ìºì‹œ ë¯¸ìŠ¤, ë‘ ë²ˆì§¸: ìºì‹œ íˆíŠ¸)")
        print()
        
        # Phase 1: ì²« ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ ë¯¸ìŠ¤)
        print("ğŸ”¥ Phase 1: ì²« ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ ë¯¸ìŠ¤)")
        print("-" * 40)
        
        first_run_times = []
        
        for i, query in enumerate(test_queries, 1):
            print(f"  ğŸ§ª í…ŒìŠ¤íŠ¸ {i}: {query[:30]}...")
            
            start_time = time.time()
            result = await hybrid_pipeline.answer_with_hybrid_search(
                query, k=5, use_query_rewriting=False
            )
            elapsed_time = time.time() - start_time
            first_run_times.append(elapsed_time)
            
            print(f"      â±ï¸  ì‹œê°„: {elapsed_time:.3f}ì´ˆ")
            print(f"      ğŸ“ ë‹µë³€ ê¸¸ì´: {len(result.get('answer', ''))}")
            print(f"      ğŸ¯ ì‹ ë¢°ë„: {result.get('confidence', 'UNKNOWN')}")
            print()
        
        # ì¤‘ê°„ í†µê³„
        avg_first_run = sum(first_run_times) / len(first_run_times)
        print(f"ğŸ“ˆ ì²« ë²ˆì§¸ ì‹¤í–‰ í‰ê·  ì‹œê°„: {avg_first_run:.3f}ì´ˆ")
        print()
        
        # ì ì‹œ ëŒ€ê¸° (ìºì‹œ ì•ˆì •í™”)
        await asyncio.sleep(1)
        
        # Phase 2: ë‘ ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ íˆíŠ¸)
        print("âš¡ Phase 2: ë‘ ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ íˆíŠ¸)")
        print("-" * 40)
        
        second_run_times = []
        
        for i, query in enumerate(test_queries, 1):
            print(f"  ğŸ§ª í…ŒìŠ¤íŠ¸ {i}: {query[:30]}...")
            
            start_time = time.time()
            result = await hybrid_pipeline.answer_with_hybrid_search(
                query, k=5, use_query_rewriting=False
            )
            elapsed_time = time.time() - start_time
            second_run_times.append(elapsed_time)
            
            print(f"      â±ï¸  ì‹œê°„: {elapsed_time:.3f}ì´ˆ")
            print(f"      ğŸ“ ë‹µë³€ ê¸¸ì´: {len(result.get('answer', ''))}")
            print(f"      ğŸ¯ ì‹ ë¢°ë„: {result.get('confidence', 'UNKNOWN')}")
            
            # ì„±ëŠ¥ í–¥ìƒ ê³„ì‚°
            if first_run_times[i-1] > 0:
                improvement = ((first_run_times[i-1] - elapsed_time) / first_run_times[i-1]) * 100
                print(f"      ğŸš€ ì„±ëŠ¥ í–¥ìƒ: {improvement:.1f}%")
            print()
        
        # Phase 3: í˜¼í•© íŒ¨í„´ í…ŒìŠ¤íŠ¸ (ìƒˆ ì¿¼ë¦¬ + ìºì‹œëœ ì¿¼ë¦¬)
        print("ğŸ”„ Phase 3: í˜¼í•© íŒ¨í„´ í…ŒìŠ¤íŠ¸")
        print("-" * 40)
        
        mixed_queries = [
            "MOJI ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜",  # ìƒˆ ì¿¼ë¦¬
            test_queries[0],  # ìºì‹œëœ ì¿¼ë¦¬
            "ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ì›ì¹™",  # ìƒˆ ì¿¼ë¦¬
            test_queries[1],  # ìºì‹œëœ ì¿¼ë¦¬
        ]
        
        mixed_times = []
        for i, query in enumerate(mixed_queries, 1):
            is_cached = query in test_queries
            print(f"  ğŸ§ª í…ŒìŠ¤íŠ¸ {i}: {query[:30]}... ({'ìºì‹œ' if is_cached else 'ì‹ ê·œ'})")
            
            start_time = time.time()
            result = await hybrid_pipeline.answer_with_hybrid_search(
                query, k=5, use_query_rewriting=False
            )
            elapsed_time = time.time() - start_time
            mixed_times.append(elapsed_time)
            
            print(f"      â±ï¸  ì‹œê°„: {elapsed_time:.3f}ì´ˆ")
            if is_cached:
                print(f"      âœ… ìºì‹œ íˆíŠ¸")
            else:
                print(f"      ğŸ†• ì‹ ê·œ ì²˜ë¦¬")
            print()
        
        # ìµœì¢… í†µê³„ ë° ë¶„ì„
        print("ğŸ“Š ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼")
        print("=" * 50)
        
        avg_second_run = sum(second_run_times) / len(second_run_times)
        avg_mixed = sum(mixed_times) / len(mixed_times)
        
        print(f"ğŸ“ˆ í‰ê·  ì‘ë‹µ ì‹œê°„:")
        print(f"  - ì²« ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ ë¯¸ìŠ¤): {avg_first_run:.3f}ì´ˆ")
        print(f"  - ë‘ ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ íˆíŠ¸): {avg_second_run:.3f}ì´ˆ")
        print(f"  - í˜¼í•© íŒ¨í„´: {avg_mixed:.3f}ì´ˆ")
        print()
        
        # ì„±ëŠ¥ í–¥ìƒ ê³„ì‚°
        if avg_first_run > 0:
            cache_improvement = ((avg_first_run - avg_second_run) / avg_first_run) * 100
            print(f"ğŸš€ ìºì‹œë¡œ ì¸í•œ ì„±ëŠ¥ í–¥ìƒ: {cache_improvement:.1f}%")
        
        # ì†ë„ í–¥ìƒ ë¹„ìœ¨
        if avg_second_run > 0:
            speedup_ratio = avg_first_run / avg_second_run
            print(f"âš¡ ì†ë„ í–¥ìƒ ë¹„ìœ¨: {speedup_ratio:.1f}x")
        
        print()
        
        # ìºì‹œ í†µê³„
        cache_stats = get_cache_stats()
        print(f"ğŸ’¾ ìºì‹œ ì‹œìŠ¤í…œ í†µê³„:")
        print(f"  - ìºì‹œ íƒ€ì…: {cache_stats.get('type', 'unknown')}")
        if cache_stats.get('hit_ratio') is not None:
            print(f"  - íˆíŠ¸ìœ¨: {cache_stats['hit_ratio']:.1%}")
        if cache_stats.get('size') is not None:
            print(f"  - ìºì‹œ í¬ê¸°: {cache_stats['size']}ê°œ í•­ëª©")
        print()
        
        # ì„ë² ë”© ìºì‹œ í†µê³„ (ê°€ëŠ¥í•œ ê²½ìš°)
        if hasattr(hybrid_pipeline.base_pipeline.embeddings, 'get_cache_stats'):
            embedding_stats = hybrid_pipeline.base_pipeline.embeddings.get_cache_stats()
            print(f"ğŸ”¤ ì„ë² ë”© ìºì‹œ í†µê³„:")
            print(f"  - íˆíŠ¸ìœ¨: {embedding_stats['hit_rate']:.1%}")
            print(f"  - ìºì‹œ íˆíŠ¸: {embedding_stats['cache_hits']}íšŒ")
            print(f"  - ìºì‹œ ë¯¸ìŠ¤: {embedding_stats['cache_misses']}íšŒ")
            print()
        
        # ê¶Œì¥ì‚¬í•­
        print(f"ğŸ’¡ ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­:")
        if cache_improvement > 70:
            print(f"  âœ… ìºì‹œ ì‹œìŠ¤í…œì´ ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤!")
            print(f"  ğŸ“ˆ {cache_improvement:.0f}% ì„±ëŠ¥ í–¥ìƒìœ¼ë¡œ ì‚¬ìš©ì ê²½í—˜ í¬ê²Œ ê°œì„ ")
        elif cache_improvement > 40:
            print(f"  ğŸ”„ ìºì‹œ ì‹œìŠ¤í…œì´ íš¨ê³¼ì ì…ë‹ˆë‹¤")
            print(f"  ğŸ“Š {cache_improvement:.0f}% ì„±ëŠ¥ í–¥ìƒ, ì¶”ê°€ ìµœì í™” ê°€ëŠ¥")
        else:
            print(f"  âš ï¸  ìºì‹œ íš¨ê³¼ê°€ ì œí•œì ì…ë‹ˆë‹¤")
            print(f"  ğŸ”§ ìºì‹œ ì„¤ì • ë˜ëŠ” TTL ì¡°ì • í•„ìš”")
        
        print(f"\nğŸ¯ ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:")
        print(f"  - ìì£¼ ë¬»ëŠ” ì§ˆë¬¸: 0.1-0.3ì´ˆë¡œ ì¦‰ì‹œ ì‘ë‹µ")
        print(f"  - ìƒˆë¡œìš´ ì§ˆë¬¸: {avg_first_run:.1f}ì´ˆ (ê¸°ì¡´ ëŒ€ë¹„)")
        print(f"  - ì „ì²´ í‰ê· : ì•½ {(avg_first_run + avg_second_run) / 2:.1f}ì´ˆ")
        
        print(f"\nâœ… ìºì‹± ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()


async def test_cache_ttl():
    """ìºì‹œ TTL(Time To Live) í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ• ìºì‹œ TTL í…ŒìŠ¤íŠ¸")
    print("=" * 30)
    
    try:
        from app.core.cache import cache_manager
        
        # ì§§ì€ TTLë¡œ í…ŒìŠ¤íŠ¸ (5ì´ˆ)
        test_query = "TTL í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬"
        test_result = {"answer": "í…ŒìŠ¤íŠ¸ ì‘ë‹µ", "cached_at": time.time()}
        
        print("ğŸ“ 5ì´ˆ TTLë¡œ ìºì‹œ ì €ì¥...")
        await cache_manager.set_query_result(test_query, {}, test_result, ttl=5)
        
        # ì¦‰ì‹œ ì¡°íšŒ (íˆíŠ¸ ì˜ˆìƒ)
        cached = await cache_manager.get_query_result(test_query, {})
        if cached:
            print("âœ… ì¦‰ì‹œ ì¡°íšŒ: ìºì‹œ íˆíŠ¸")
        else:
            print("âŒ ì¦‰ì‹œ ì¡°íšŒ: ìºì‹œ ë¯¸ìŠ¤")
        
        print("â³ 6ì´ˆ ëŒ€ê¸° ì¤‘...")
        await asyncio.sleep(6)
        
        # ë§Œë£Œ í›„ ì¡°íšŒ (ë¯¸ìŠ¤ ì˜ˆìƒ)
        expired = await cache_manager.get_query_result(test_query, {})
        if expired:
            print("âŒ ë§Œë£Œ í›„ ì¡°íšŒ: ìºì‹œê°€ ë§Œë£Œë˜ì§€ ì•ŠìŒ")
        else:
            print("âœ… ë§Œë£Œ í›„ ì¡°íšŒ: ìºì‹œ ì •ìƒ ë§Œë£Œ")
        
    except Exception as e:
        print(f"âŒ TTL í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")


if __name__ == "__main__":
    async def main():
        await test_caching_performance()
        await test_cache_ttl()
    
    asyncio.run(main())