#!/usr/bin/env python3
"""
ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (LLM ì—†ì´)
DOCX íŒŒì¼ ë‚´ìš©ì´ ë²¡í„° DBì— ì˜¬ë°”ë¥´ê²Œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
"""

import os
import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

def test_vector_search():
    """ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (LLM ì—†ì´)")
    print("=" * 50)
    
    try:
        # í™˜ê²½ ì„¤ì •
        from app.core.config import settings
        if settings.openai_api_key:
            os.environ['OPENAI_API_KEY'] = settings.openai_api_key
        elif settings.llm_api_key:
            os.environ['OPENAI_API_KEY'] = settings.llm_api_key
        
        from app.rag.enhanced_rag import rag_pipeline
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
        test_queries = [
            "MOJI í…ŒìŠ¤íŠ¸",
            "í…ŒìŠ¤íŠ¸ ë¬¸ì„œ",
            "AI ì–´ì‹œìŠ¤í„´íŠ¸",
            "SMHACCP",
            "íšŒì‚¬ì†Œê°œ"
        ]
        
        print(f"ğŸ“Š ë²¡í„° DB ìƒíƒœ:")
        stats = rag_pipeline.get_collection_stats()
        print(f"  - ì´ ë¬¸ì„œ ìˆ˜: {stats.get('total_documents', 0)}")
        print(f"  - ì„ë² ë”© ëª¨ë¸: {stats.get('embedding_model', 'Unknown')}")
        print()
        
        for query in test_queries:
            print(f"ğŸ” ê²€ìƒ‰ì–´: '{query}'")
            
            try:
                # ì§ì ‘ ë²¡í„° ê²€ìƒ‰ (LLM ì—†ì´)
                results = rag_pipeline.vectorstore.similarity_search_with_score(query, k=3)
                
                if results:
                    print(f"  âœ… ë°œê²¬ëœ ê²°ê³¼: {len(results)}ê°œ")
                    for i, (doc, score) in enumerate(results, 1):
                        source = doc.metadata.get('file_name', 'Unknown')
                        content_preview = doc.page_content[:100].replace('\n', ' ')
                        print(f"    {i}. ì¶œì²˜: {source}")
                        print(f"       ì ìˆ˜: {score:.4f}")
                        print(f"       ë‚´ìš©: {content_preview}...")
                        print()
                else:
                    print(f"  âŒ ê²°ê³¼ ì—†ìŒ")
                    
            except Exception as e:
                print(f"  âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
            
            print("-" * 40)
        
        # DOCX íŒŒì¼ íŠ¹ë³„ í™•ì¸
        print(f"\nğŸ“‹ DOCX íŒŒì¼ í™•ì¸:")
        docx_query = "MOJI í…ŒìŠ¤íŠ¸ ë¬¸ì„œ"
        results = rag_pipeline.vectorstore.similarity_search_with_score(docx_query, k=5)
        
        docx_results = []
        for doc, score in results:
            source = doc.metadata.get('source', '')
            if source.endswith('.docx'):
                docx_results.append((doc, score))
        
        if docx_results:
            print(f"  âœ… DOCX íŒŒì¼ì—ì„œ ë°œê²¬: {len(docx_results)}ê°œ")
            for doc, score in docx_results:
                source = doc.metadata.get('file_name', 'Unknown')
                print(f"    - {source} (ì ìˆ˜: {score:.4f})")
                print(f"      ë‚´ìš©: {doc.page_content[:200]}...")
                print()
        else:
            print(f"  âš ï¸  DOCX íŒŒì¼ì—ì„œ ì§ì ‘ ë§¤ì¹˜ ì—†ìŒ")
            print(f"  ğŸ’¡ ì „ì²´ ê²°ê³¼:")
            for i, (doc, score) in enumerate(results[:3], 1):
                source = doc.metadata.get('file_name', 'Unknown')
                print(f"    {i}. {source} (ì ìˆ˜: {score:.4f})")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_vector_search()