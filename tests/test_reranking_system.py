#!/usr/bin/env python3
"""
ë¦¬ë­í‚¹ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
êµì°¨ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰ ê²°ê³¼ ì¬ì •ë ¬ì˜ íš¨ê³¼ ê²€ì¦
"""

import asyncio
import os
import sys
import time
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))


async def test_reranking_system():
    """ë¦¬ë­í‚¹ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸"""
    print("ğŸ”„ ë¦¬ë­í‚¹ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    try:
        # í™˜ê²½ ì„¤ì •
        from app.core.config import settings

        if settings.openai_api_key:
            os.environ["OPENAI_API_KEY"] = settings.openai_api_key
        elif settings.llm_api_key:
            os.environ["OPENAI_API_KEY"] = settings.llm_api_key

        from app.rag.enhanced_rag import rag_pipeline, get_hybrid_pipeline
        from app.rag.reranker import get_global_reranker

        # í•˜ì´ë¸Œë¦¬ë“œ/ë¦¬ë­í‚¹ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        hybrid_pipeline = get_hybrid_pipeline()
        reranker = get_global_reranker()

        print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   - ë¦¬ë­ì»¤ ëª¨ë¸: {reranker.cross_encoder.model_name}")
        print(f"   - ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©: {reranker.cross_encoder.use_local_model}")
        print()

        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤ (ë‹¤ì–‘í•œ ë‚œì´ë„ì™€ íƒ€ì…)
        test_queries = [
            {
                "query": "MOJI AI ì—ì´ì „íŠ¸ì˜ í•µì‹¬ ê¸°ëŠ¥",
                "description": "ëª…í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­",
                "expected_improvement": True,
            },
            {
                "query": "í”„ë¡œì íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ì¥ì ê³¼ íŠ¹ì§•",
                "description": "ë³µí•© ê°œë… ê²€ìƒ‰",
                "expected_improvement": True,
            },
            {
                "query": "ì‹í’ˆì œì¡°ì—… ë¬¸ì œì  í•´ê²° ë°©ì•ˆ",
                "description": "ë¬¸ì œ-í•´ê²° ê´€ê³„ ê²€ìƒ‰",
                "expected_improvement": True,
            },
            {
                "query": "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ë””ìì¸",
                "description": "ì¼ë°˜ì ì¸ ìš©ì–´",
                "expected_improvement": False,
            },
            {
                "query": "SMHACCP íšŒì‚¬ ì—°í˜ê³¼ ë¹„ì „",
                "description": "êµ¬ì²´ì  ì •ë³´ ê²€ìƒ‰",
                "expected_improvement": True,
            },
        ]

        print("ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¤ì •:")
        print(
            f"   - ë²¡í„° DB ë¬¸ì„œ ìˆ˜: {rag_pipeline.get_collection_stats().get('total_documents', 0)}ê°œ"
        )
        print(f"   - í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ìˆ˜: {len(test_queries)}ê°œ")
        print()

        total_improvement_count = 0
        total_rank_changes = []

        for i, test_case in enumerate(test_queries, 1):
            query = test_case["query"]
            description = test_case["description"]
            expected_improvement = test_case["expected_improvement"]

            print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ {i}: {description}")
            print(f'   ì¿¼ë¦¬: "{query}"')
            print()

            # === í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë¦¬ë­í‚¹ ì—†ìŒ) ===
            print("   ğŸ“ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë¦¬ë­í‚¹ ì—†ìŒ)")
            start_time = time.time()

            try:
                no_rerank_docs, no_rerank_meta = (
                    await hybrid_pipeline.search_with_hybrid(
                        query, k=10, use_reranking=False
                    )
                )
                no_rerank_time = time.time() - start_time

                print(f"      â±ï¸  ì‹œê°„: {no_rerank_time:.3f}ì´ˆ")
                print(f"      ğŸ“„ ê²°ê³¼: {len(no_rerank_docs)}ê°œ")

                # ìƒìœ„ 3ê°œ ê²°ê³¼ í‘œì‹œ
                if no_rerank_meta.get("result_details"):
                    print("      ğŸ“‹ ìƒìœ„ 3ê°œ:")
                    for j, detail in enumerate(no_rerank_meta["result_details"][:3], 1):
                        source = Path(detail.get("source", "Unknown")).name
                        score = detail.get("combined_score", 0)
                        print(f"         {j}. {source} (ì ìˆ˜: {score:.4f})")

            except Exception as e:
                print(f"      âŒ ì˜¤ë¥˜: {str(e)}")
                continue

            print()

            # === í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + ë¦¬ë­í‚¹ ===
            print("   ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + ë¦¬ë­í‚¹")
            start_time = time.time()

            try:
                rerank_docs, rerank_meta = await hybrid_pipeline.search_with_hybrid(
                    query, k=10, use_reranking=True
                )
                rerank_time = time.time() - start_time

                print(f"      â±ï¸  ì‹œê°„: {rerank_time:.3f}ì´ˆ")
                print(f"      ğŸ“„ ê²°ê³¼: {len(rerank_docs)}ê°œ")
                print(
                    f"      ğŸ” ê²€ìƒ‰ íƒ€ì…: {rerank_meta.get('search_type', 'unknown')}"
                )

                # ìƒìœ„ 3ê°œ ê²°ê³¼ í‘œì‹œ (ë¦¬ë­í‚¹ ì •ë³´ í¬í•¨)
                if rerank_meta.get("result_details"):
                    print("      ğŸ“‹ ìƒìœ„ 3ê°œ (ë¦¬ë­í‚¹ í›„):")
                    rank_changes = []

                    for j, detail in enumerate(rerank_meta["result_details"][:3], 1):
                        source = Path(detail.get("source", "Unknown")).name
                        breakdown = detail.get("score_breakdown", {})

                        final_score = breakdown.get(
                            "final_score", breakdown.get("combined_score", 0)
                        )
                        rerank_score = breakdown.get("rerank_score", 0)
                        rank_change = breakdown.get("rank_change", 0)

                        rank_changes.append(rank_change)

                        change_indicator = ""
                        if rank_change > 0:
                            change_indicator = f" â¬†ï¸+{rank_change}"
                        elif rank_change < 0:
                            change_indicator = f" â¬‡ï¸{rank_change}"

                        print(
                            f"         {j}. {source} (ì ìˆ˜: {final_score:.4f}){change_indicator}"
                        )
                        if rerank_score > 0:
                            print(f"            ë¦¬ë­í¬: {rerank_score:.3f}")

                    # ìˆœìœ„ ë³€í™” ë¶„ì„
                    positive_changes = sum(1 for change in rank_changes if change > 0)
                    negative_changes = sum(1 for change in rank_changes if change < 0)
                    avg_rank_change = sum(abs(change) for change in rank_changes) / len(
                        rank_changes
                    )

                    print(
                        f"      ğŸ“ˆ ìˆœìœ„ ë³€í™”: ìƒìŠ¹ {positive_changes}ê°œ, í•˜ë½ {negative_changes}ê°œ"
                    )
                    print(f"      ğŸ“Š í‰ê·  ìˆœìœ„ ë³€í™”: {avg_rank_change:.1f}")

                    total_rank_changes.extend(rank_changes)

                    # ê°œì„  ì—¬ë¶€ íŒë‹¨
                    improvement_detected = (
                        avg_rank_change > 0.5 or positive_changes > negative_changes
                    )
                    if improvement_detected:
                        total_improvement_count += 1
                        print("      âœ… ë¦¬ë­í‚¹ íš¨ê³¼ ê°ì§€ë¨")
                    else:
                        print("      â– ë¦¬ë­í‚¹ íš¨ê³¼ ë¯¸ë¯¸")

            except Exception as e:
                print(f"      âŒ ì˜¤ë¥˜: {str(e)}")
                continue

            # ì„±ëŠ¥ ë¹„êµ
            performance_overhead = (
                ((rerank_time - no_rerank_time) / no_rerank_time) * 100
                if no_rerank_time > 0
                else 0
            )
            print(
                f"   â±ï¸  ì„±ëŠ¥ ì˜¤ë²„í—¤ë“œ: +{performance_overhead:.1f}% ({rerank_time:.3f}ì´ˆ vs {no_rerank_time:.3f}ì´ˆ)"
            )

            # ì˜ˆìƒ vs ì‹¤ì œ ë¹„êµ
            if expected_improvement:
                if improvement_detected:
                    print("   ğŸ¯ ì˜ˆìƒëŒ€ë¡œ ê°œì„ ë¨")
                else:
                    print("   âš ï¸  ì˜ˆìƒê³¼ ë‹¬ë¦¬ ê°œì„  ë¯¸ë¯¸")
            else:
                if not improvement_detected:
                    print("   ğŸ¯ ì˜ˆìƒëŒ€ë¡œ ë³€í™” ì—†ìŒ")
                else:
                    print("   ğŸŒŸ ì˜ˆìƒë³´ë‹¤ ì¢‹ì€ ê°œì„ ")

            print("-" * 50)

        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        print("\nğŸ“ˆ ë¦¬ë­í‚¹ ì‹œìŠ¤í…œ í‰ê°€ ê²°ê³¼:")
        print(f"   ğŸ”„ ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {len(test_queries)}ê°œ")
        print(f"   âœ… ê°œì„  ê°ì§€ëœ ì¿¼ë¦¬: {total_improvement_count}ê°œ")
        print(
            f"   ğŸ“Š ì „ì²´ ê°œì„ ìœ¨: {(total_improvement_count / len(test_queries)) * 100:.1f}%"
        )

        if total_rank_changes:
            positive_total = sum(1 for change in total_rank_changes if change > 0)
            negative_total = sum(1 for change in total_rank_changes if change < 0)
            avg_total_change = sum(abs(change) for change in total_rank_changes) / len(
                total_rank_changes
            )

            print("   ğŸ“ˆ ì „ì²´ ìˆœìœ„ ë³€í™”:")
            print(f"      - ìƒìŠ¹: {positive_total}ê°œ ë¬¸ì„œ")
            print(f"      - í•˜ë½: {negative_total}ê°œ ë¬¸ì„œ")
            print(f"      - í‰ê·  ë³€í™”: {avg_total_change:.1f}")

        # ì‹œìŠ¤í…œ ì„±ëŠ¥ ì •ë³´
        print("\nğŸ’¾ ì‹œìŠ¤í…œ ì„±ëŠ¥:")
        try:
            import psutil

            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            print(f"   ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_mb:.1f} MB")
        except ImportError:
            print("   âš ï¸  psutil ì—†ìŒ - ë©”ëª¨ë¦¬ ì •ë³´ í™•ì¸ ë¶ˆê°€")

        # ê¶Œì¥ì‚¬í•­
        print("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        if total_improvement_count >= len(test_queries) * 0.6:
            print("   ğŸŒŸ ë¦¬ë­í‚¹ ì‹œìŠ¤í…œì´ íš¨ê³¼ì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤!")
            print("   âœ… í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ë¦¬ë­í‚¹ í™œì„±í™” ê¶Œì¥")
        elif total_improvement_count >= len(test_queries) * 0.3:
            print("   ğŸ”„ ë¦¬ë­í‚¹ ì‹œìŠ¤í…œì´ ë¶€ë¶„ì ìœ¼ë¡œ íš¨ê³¼ì ì…ë‹ˆë‹¤")
            print("   ğŸ¯ íŠ¹ì • ì¿¼ë¦¬ íƒ€ì…ì— ëŒ€í•´ ì„ íƒì  í™œìš© ê³ ë ¤")
        else:
            print("   âš ï¸  í˜„ì¬ ë°ì´í„°ì…‹ì—ì„œëŠ” ë¦¬ë­í‚¹ íš¨ê³¼ê°€ ì œí•œì ì…ë‹ˆë‹¤")
            print("   ğŸ”§ ëª¨ë¸ íŠœë‹ì´ë‚˜ ë‹¤ë¥¸ ë¦¬ë­í‚¹ ì „ëµ ê²€í†  í•„ìš”")

        print("\nâœ… ë¦¬ë­í‚¹ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")
        import traceback

        traceback.print_exc()


async def test_reranker_models():
    """ë‹¤ì–‘í•œ ë¦¬ë­ì»¤ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"""
    print("\nğŸ”¬ ë¦¬ë­ì»¤ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
    print("=" * 40)

    try:
        from app.rag.reranker import CrossEncoderReranker
        from app.rag.enhanced_rag import rag_pipeline

        # í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ë¬¸ì„œì™€ ì¿¼ë¦¬
        test_query = "MOJI AI ì—ì´ì „íŠ¸ ê¸°ëŠ¥"

        # ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        docs_with_scores = rag_pipeline.vectorstore.similarity_search_with_score(
            test_query, k=5
        )
        docs = [doc for doc, _ in docs_with_scores]
        original_scores = [
            1.0 / (1.0 + score) for _, score in docs_with_scores
        ]  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜

        if not docs:
            print("âš ï¸  í…ŒìŠ¤íŠ¸í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
            return

        print(f"ğŸ“„ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ: {len(docs)}ê°œ")
        print(f'ğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: "{test_query}"')
        print()

        # ëª¨ë¸ë³„ í…ŒìŠ¤íŠ¸
        model_configs = [
            {
                "name": "MS Marco MiniLM",
                "model_name": "ms-marco-MiniLM-L-6-v2",
                "description": "ê²½ëŸ‰ ì˜ì–´ íŠ¹í™” ëª¨ë¸",
            },
            {
                "name": "Cross-encoder Official",
                "model_name": "cross-encoder/ms-marco-MiniLM-L-6-v2",
                "description": "ê³µì‹ êµì°¨ ì¸ì½”ë”",
            },
            {
                "name": "Fallback Similarity",
                "model_name": "fallback",
                "description": "í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ í´ë°±",
                "use_local_model": False,
            },
        ]

        for config in model_configs:
            print(f"ğŸ§ª í…ŒìŠ¤íŠ¸: {config['name']}")
            print(f"   ì„¤ëª…: {config['description']}")

            try:
                start_time = time.time()

                # ë¦¬ë­ì»¤ ìƒì„±
                if config.get("use_local_model", True):
                    reranker = CrossEncoderReranker(
                        model_name=config["model_name"], use_local_model=True
                    )
                else:
                    reranker = CrossEncoderReranker(use_local_model=False)

                # ë¦¬ë­í‚¹ ì‹¤í–‰
                results = reranker.rerank(test_query, docs, original_scores, top_k=3)
                elapsed_time = time.time() - start_time

                print(f"   â±ï¸  ì²˜ë¦¬ ì‹œê°„: {elapsed_time:.3f}ì´ˆ")
                print(f"   ğŸ“Š ê²°ê³¼ ìˆ˜: {len(results)}ê°œ")

                if results:
                    print("   ğŸ“‹ ìƒìœ„ 3ê°œ ê²°ê³¼:")
                    for i, result in enumerate(results[:3], 1):
                        source = Path(
                            result.document.metadata.get("source", "Unknown")
                        ).name
                        change_indicator = ""
                        if result.rank_change > 0:
                            change_indicator = f" â¬†ï¸+{result.rank_change}"
                        elif result.rank_change < 0:
                            change_indicator = f" â¬‡ï¸{result.rank_change}"

                        print(f"      {i}. {source}")
                        print(
                            f"         ì›ë³¸: {result.original_score:.3f}, ë¦¬ë­í¬: {result.rerank_score:.3f}"
                        )
                        print(
                            f"         ìµœì¢…: {result.combined_score:.3f}{change_indicator}"
                        )

                # ìˆœìœ„ ë³€í™” í†µê³„
                rank_changes = [r.rank_change for r in results]
                avg_change = (
                    sum(abs(change) for change in rank_changes) / len(rank_changes)
                    if rank_changes
                    else 0
                )
                print(f"   ğŸ“ˆ í‰ê·  ìˆœìœ„ ë³€í™”: {avg_change:.1f}")

            except Exception as e:
                print(f"   âŒ ì˜¤ë¥˜: {str(e)}")

            print()

    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")


if __name__ == "__main__":

    async def main():
        await test_reranking_system()
        await test_reranker_models()

    asyncio.run(main())
