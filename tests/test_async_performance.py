#!/usr/bin/env python3
"""
ë¹„ë™ê¸° ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
ë³‘ë ¬ ê²€ìƒ‰ vs ìˆœì°¨ ê²€ìƒ‰ ì„±ëŠ¥ ë¹„êµ
"""

import asyncio
import os
import sys
import time
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))


async def test_parallel_vs_sequential():
    """ë³‘ë ¬ vs ìˆœì°¨ ê²€ìƒ‰ ì„±ëŠ¥ ë¹„êµ"""
    print("âš¡ ë³‘ë ¬ vs ìˆœì°¨ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    try:
        # í™˜ê²½ ì„¤ì •
        from app.core.config import settings

        if settings.openai_api_key:
            os.environ["OPENAI_API_KEY"] = settings.openai_api_key
        elif settings.llm_api_key:
            os.environ["OPENAI_API_KEY"] = settings.llm_api_key

        from app.rag.enhanced_rag import rag_pipeline, get_hybrid_pipeline
        from app.core.cache import clear_cache

        # ìºì‹œ ì´ˆê¸°í™” (ê³µì •í•œ ë¹„êµë¥¼ ìœ„í•´)
        await clear_cache()
        print("âœ… ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")

        hybrid_pipeline = get_hybrid_pipeline()

        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ (ì¿¼ë¦¬ ì¬ì‘ì„±ì´ í™œì„±í™”ë˜ì–´ ì—¬ëŸ¬ ì¿¼ë¦¬ ìƒì„±)
        test_queries = [
            "MOJI AI ì—ì´ì „íŠ¸ì˜ í•µì‹¬ ê¸°ëŠ¥ê³¼ íŠ¹ì§•",
            "SMHACCP íšŒì‚¬ì˜ ì‚¬ì—… ì˜ì—­ê³¼ ë¹„ì „",
            "í”„ë¡œì íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ì£¼ìš” ì¥ì ",
        ]

        print("ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¤ì •:")
        print(f"  - í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {len(test_queries)}ê°œ")
        print("  - ê° ì¿¼ë¦¬ëŠ” ì—¬ëŸ¬ ë³€í˜•ìœ¼ë¡œ ì¬ì‘ì„±ë¨")
        print("  - ë³‘ë ¬ vs ìˆœì°¨ ì²˜ë¦¬ ë¹„êµ")
        print()

        for i, query in enumerate(test_queries, 1):
            print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ {i}: {query[:30]}...")
            print("-" * 40)

            # === ìˆœì°¨ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===
            print("ğŸ“ ìˆœì°¨ ê²€ìƒ‰ (ê¸°ì¡´ ë°©ì‹)")
            start_time = time.time()

            try:
                # ë³‘ë ¬ ê²€ìƒ‰ ë¹„í™œì„±í™”
                sequential_docs, sequential_meta = (
                    await rag_pipeline.search_with_rewriting(
                        query, k=5, use_parallel_search=False
                    )
                )
                sequential_time = time.time() - start_time

                print(f"   â±ï¸  ì‹œê°„: {sequential_time:.3f}ì´ˆ")
                print(f"   ğŸ“„ ê²°ê³¼: {len(sequential_docs)}ê°œ")
                print(
                    f"   ğŸ”„ ì¬ì‘ì„± ì¿¼ë¦¬: {len(sequential_meta.get('rewritten_queries', []))}ê°œ"
                )

            except Exception as e:
                print(f"   âŒ ìˆœì°¨ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
                sequential_time = float("inf")
                continue

            # ì ì‹œ ëŒ€ê¸° (ì‹œìŠ¤í…œ ì•ˆì •í™”)
            await asyncio.sleep(0.5)

            # === ë³‘ë ¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===
            print("\nâš¡ ë³‘ë ¬ ê²€ìƒ‰ (ê°œì„ ëœ ë°©ì‹)")
            start_time = time.time()

            try:
                # ë³‘ë ¬ ê²€ìƒ‰ í™œì„±í™”
                parallel_docs, parallel_meta = await rag_pipeline.search_with_rewriting(
                    query, k=5, use_parallel_search=True
                )
                parallel_time = time.time() - start_time

                print(f"   â±ï¸  ì‹œê°„: {parallel_time:.3f}ì´ˆ")
                print(f"   ğŸ“„ ê²°ê³¼: {len(parallel_docs)}ê°œ")
                print(
                    f"   ğŸ”„ ì¬ì‘ì„± ì¿¼ë¦¬: {len(parallel_meta.get('rewritten_queries', []))}ê°œ"
                )

                # ì„±ëŠ¥ ë¹„êµ
                if sequential_time > 0 and sequential_time != float("inf"):
                    improvement = (
                        (sequential_time - parallel_time) / sequential_time
                    ) * 100
                    speedup = (
                        sequential_time / parallel_time
                        if parallel_time > 0
                        else float("inf")
                    )

                    print("\nğŸ“Š ì„±ëŠ¥ ë¹„êµ:")
                    print(f"   ğŸš€ ì„±ëŠ¥ í–¥ìƒ: {improvement:.1f}%")
                    print(f"   âš¡ ì†ë„ í–¥ìƒ: {speedup:.1f}x")

                    if improvement > 20:
                        print("   âœ… ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼ ìš°ìˆ˜")
                    elif improvement > 0:
                        print("   ğŸ”„ ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼ ì–‘í˜¸")
                    else:
                        print("   âš ï¸  ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼ ì œí•œì ")

            except Exception as e:
                print(f"   âŒ ë³‘ë ¬ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")

            print("=" * 50)

        print("\nğŸ¯ ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™” ì™„ë£Œ!")

    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")
        import traceback

        traceback.print_exc()


async def test_hybrid_parallel_performance():
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë³‘ë ¬ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë³‘ë ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    try:
        from app.rag.enhanced_rag import get_hybrid_pipeline
        from app.core.cache import clear_cache

        # ìºì‹œ ì´ˆê¸°í™”
        await clear_cache()

        hybrid_pipeline = get_hybrid_pipeline()

        test_query = "MOJI AI ì‹œìŠ¤í…œì˜ ì „ì²´ì ì¸ ì•„í‚¤í…ì²˜ì™€ êµ¬ì„± ìš”ì†Œ"

        print(f'ğŸ“ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: "{test_query}"')
        print()

        # === ì¿¼ë¦¬ ì¬ì‘ì„± ì—†ì´ (ë‹¨ì¼ ì¿¼ë¦¬) ===
        print("ğŸ“ ë‹¨ì¼ ì¿¼ë¦¬ ëª¨ë“œ (ì¬ì‘ì„± ì—†ìŒ)")
        start_time = time.time()

        single_docs, single_meta = await hybrid_pipeline.search_with_hybrid(
            test_query, k=5, use_query_rewriting=False
        )
        single_time = time.time() - start_time

        print(f"   â±ï¸  ì‹œê°„: {single_time:.3f}ì´ˆ")
        print(f"   ğŸ“„ ê²°ê³¼: {len(single_docs)}ê°œ")
        print(f"   ğŸ” ê²€ìƒ‰ íƒ€ì…: {single_meta.get('search_type', 'unknown')}")

        # === ì¿¼ë¦¬ ì¬ì‘ì„± + ë³‘ë ¬ ì²˜ë¦¬ ===
        print("\nâš¡ ë‹¤ì¤‘ ì¿¼ë¦¬ + ë³‘ë ¬ ì²˜ë¦¬")
        start_time = time.time()

        parallel_docs, parallel_meta = await hybrid_pipeline.search_with_hybrid(
            test_query, k=5, use_query_rewriting=True  # ì¿¼ë¦¬ ì¬ì‘ì„± í™œì„±í™”
        )
        parallel_time = time.time() - start_time

        print(f"   â±ï¸  ì‹œê°„: {parallel_time:.3f}ì´ˆ")
        print(f"   ğŸ“„ ê²°ê³¼: {len(parallel_docs)}ê°œ")
        print(f"   ğŸ” ê²€ìƒ‰ íƒ€ì…: {parallel_meta.get('search_type', 'unknown')}")
        print(f"   ğŸ”„ ì¬ì‘ì„± ì¿¼ë¦¬: {len(parallel_meta.get('rewritten_queries', []))}ê°œ")
        print(f"   ğŸ“Š ì´ í›„ë³´: {parallel_meta.get('total_results', 0)}ê°œ")

        # ë¹„ìœ¨ ë¶„ì„
        if single_time > 0:
            overhead_ratio = parallel_time / single_time
            print("\nğŸ“Š ì˜¤ë²„í—¤ë“œ ë¶„ì„:")
            print(f"   ğŸ“ˆ ì²˜ë¦¬ ì‹œê°„ ë¹„ìœ¨: {overhead_ratio:.1f}x")

            if overhead_ratio < 2.0:
                print("   âœ… ì¿¼ë¦¬ í™•ì¥ ëŒ€ë¹„ ì˜¤ë²„í—¤ë“œ í•©ë¦¬ì ")
            elif overhead_ratio < 3.0:
                print("   ğŸ”„ ì¿¼ë¦¬ í™•ì¥ ëŒ€ë¹„ ì˜¤ë²„í—¤ë“œ ë³´í†µ")
            else:
                print("   âš ï¸  ì¿¼ë¦¬ í™•ì¥ ëŒ€ë¹„ ì˜¤ë²„í—¤ë“œ ë†’ìŒ")

        # í’ˆì§ˆ ë¹„êµ
        print("\nğŸ¯ ê²€ìƒ‰ í’ˆì§ˆ ë¹„êµ:")
        print(f"   ë‹¨ì¼ ì¿¼ë¦¬: {len(single_docs)}ê°œ ê²°ê³¼")
        print(f"   ë‹¤ì¤‘ ì¿¼ë¦¬: {len(parallel_docs)}ê°œ ê²°ê³¼")

        if len(parallel_docs) > len(single_docs):
            print("   âœ… ë‹¤ì¤‘ ì¿¼ë¦¬ë¡œ ë” ë§ì€ ê´€ë ¨ ë¬¸ì„œ ë°œê²¬")
        elif len(parallel_docs) == len(single_docs):
            print("   ğŸ”„ ê²°ê³¼ ìˆ˜ëŠ” ë™ì¼, í’ˆì§ˆ ê°œì„  ê°€ëŠ¥ì„±")
        else:
            print("   âš ï¸  ë‹¤ì¤‘ ì¿¼ë¦¬ë¡œ ê²°ê³¼ ìˆ˜ ê°ì†Œ")

    except Exception as e:
        print(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")


async def test_async_batch_processing():
    """ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“¦ ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    print("=" * 40)

    try:
        from app.core.async_utils import AsyncBatchProcessor

        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_items = [f"í…ŒìŠ¤íŠ¸ í•­ëª© {i}" for i in range(20)]

        def simple_processor(batch):
            """ê°„ë‹¨í•œ ë°°ì¹˜ ì²˜ë¦¬ê¸°"""
            time.sleep(0.1)  # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
            return [f"ì²˜ë¦¬ë¨: {item}" for item in batch]

        async def async_processor(batch):
            """ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ê¸°"""
            await asyncio.sleep(0.1)  # ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
            return [f"ë¹„ë™ê¸° ì²˜ë¦¬ë¨: {item}" for item in batch]

        # ë°°ì¹˜ ì²˜ë¦¬ê¸° ìƒì„±
        batch_processor = AsyncBatchProcessor(batch_size=5, max_concurrent=3)

        # ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬
        print("ğŸ”„ ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ (ë°°ì¹˜ í¬ê¸°: 5)")
        start_time = time.time()
        sync_results = await batch_processor.process_batch(
            test_items, simple_processor, is_async=False
        )
        sync_time = time.time() - start_time

        print(f"   â±ï¸  ì‹œê°„: {sync_time:.3f}ì´ˆ")
        print(f"   ğŸ“„ ê²°ê³¼: {len(sync_results)}ê°œ")

        # ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬
        print("\nâš¡ ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ (ë°°ì¹˜ í¬ê¸°: 5)")
        start_time = time.time()
        async_results = await batch_processor.process_batch(
            test_items, async_processor, is_async=True
        )
        async_time = time.time() - start_time

        print(f"   â±ï¸  ì‹œê°„: {async_time:.3f}ì´ˆ")
        print(f"   ğŸ“„ ê²°ê³¼: {len(async_results)}ê°œ")

        # ì„±ëŠ¥ ë¹„êµ
        if sync_time > 0:
            improvement = ((sync_time - async_time) / sync_time) * 100
            print("\nğŸ“Š ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥:")
            print(f"   ğŸš€ ë¹„ë™ê¸° ì²˜ë¦¬ í–¥ìƒ: {improvement:.1f}%")

    except Exception as e:
        print(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")


if __name__ == "__main__":

    async def main():
        await test_parallel_vs_sequential()
        await test_hybrid_parallel_performance()
        await test_async_batch_processing()

        print("\nğŸ‰ ëª¨ë“  ë¹„ë™ê¸° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("ğŸ’¡ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ê²€ìƒ‰ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤!")

    asyncio.run(main())
