#!/usr/bin/env python3
"""
ëª¨ë¸ ìµœì í™” í…ŒìŠ¤íŠ¸
ì˜ˆì—´, ê²½ëŸ‰í™”, ê³µìœ  ì„±ëŠ¥ ê²€ì¦
"""

import asyncio
import os
import sys
import time
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))


async def test_model_warm_up():
    """ëª¨ë¸ ì˜ˆì—´ í…ŒìŠ¤íŠ¸"""
    print("ğŸ”¥ ëª¨ë¸ ì˜ˆì—´ í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    try:
        from app.core.model_optimization import (
            model_manager, warm_up_all_models, initialize_model_configurations
        )
        
        # ëª¨ë¸ ì„¤ì • ì´ˆê¸°í™”
        initialize_model_configurations()
        
        # ì˜ˆì—´ ì „ ìƒíƒœ í™•ì¸
        print("ğŸ“Š ì˜ˆì—´ ì „ ìƒíƒœ:")
        warm_up_status_before = {
            model_id: status for model_id, status in model_manager.warm_up_status.items()
        }
        for model_id, status in warm_up_status_before.items():
            status_icon = "âœ…" if status else "âŒ"
            print(f"   {model_id}: {status_icon}")
        
        # ëª¨ë¸ ì˜ˆì—´ ì‹¤í–‰
        print("\nğŸ”¥ ëª¨ë¸ ì˜ˆì—´ ì‹œì‘...")
        start_time = time.time()
        
        await warm_up_all_models()
        
        warm_up_time = time.time() - start_time
        
        # ì˜ˆì—´ í›„ ìƒíƒœ í™•ì¸
        print(f"\nğŸ“Š ì˜ˆì—´ ì™„ë£Œ ({warm_up_time:.3f}ì´ˆ):")
        warm_up_status_after = {
            model_id: status for model_id, status in model_manager.warm_up_status.items()
        }
        
        warmed_models = 0
        for model_id, status in warm_up_status_after.items():
            status_icon = "âœ…" if status else "âŒ"
            print(f"   {model_id}: {status_icon}")
            if status:
                warmed_models += 1
        
        # ëª¨ë¸ í†µê³„ í™•ì¸
        model_stats = model_manager.get_model_stats()
        print(f"\nğŸ“ˆ ëª¨ë¸ í†µê³„:")
        for model_id, stats in model_stats.items():
            print(f"   {model_id}:")
            print(f"     ì˜ˆì—´ ì‹œê°„: {stats.warm_up_time:.3f}ì´ˆ")
            print(f"     ì´ ìš”ì²­: {stats.total_requests}íšŒ")
        
        if warmed_models > 0:
            print(f"\nâœ… {warmed_models}ê°œ ëª¨ë¸ ì˜ˆì—´ ì„±ê³µ!")
        else:
            print(f"\nâš ï¸  ëª¨ë¸ ì˜ˆì—´ í•„ìš”")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì˜ˆì—´ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()


async def test_model_sharing():
    """ëª¨ë¸ ê³µìœ  (ì‹±ê¸€í†¤) í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ”„ ëª¨ë¸ ê³µìœ  í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    try:
        from app.core.model_optimization import (
            get_optimized_embedding_model, get_optimized_reranker_model
        )
        
        # ì„ë² ë”© ëª¨ë¸ ê³µìœ  í…ŒìŠ¤íŠ¸
        print("ğŸ“¦ ì„ë² ë”© ëª¨ë¸ ê³µìœ  í…ŒìŠ¤íŠ¸")
        start_time = time.time()
        
        model1 = get_optimized_embedding_model()
        model2 = get_optimized_embedding_model()
        model3 = get_optimized_embedding_model()
        
        sharing_time = time.time() - start_time
        
        # ë™ì¼í•œ ì¸ìŠ¤í„´ìŠ¤ì¸ì§€ í™•ì¸
        is_same_instance = (id(model1) == id(model2) == id(model3))
        
        print(f"   â±ï¸  ê°€ì ¸ì˜¤ê¸° ì‹œê°„: {sharing_time:.6f}ì´ˆ")
        print(f"   ğŸ”— ë™ì¼ ì¸ìŠ¤í„´ìŠ¤: {'âœ…' if is_same_instance else 'âŒ'}")
        print(f"   ğŸ†” ì¸ìŠ¤í„´ìŠ¤ ID: {id(model1)}")
        
        # ë¦¬ë­ì»¤ ëª¨ë¸ ê³µìœ  í…ŒìŠ¤íŠ¸ (fallback ë  ìˆ˜ ìˆìŒ)
        print(f"\nğŸ“¦ ë¦¬ë­ì»¤ ëª¨ë¸ ê³µìœ  í…ŒìŠ¤íŠ¸")
        try:
            reranker1 = get_optimized_reranker_model()
            reranker2 = get_optimized_reranker_model()
            
            reranker_same = (id(reranker1) == id(reranker2))
            print(f"   ğŸ”— ë™ì¼ ì¸ìŠ¤í„´ìŠ¤: {'âœ…' if reranker_same else 'âŒ'}")
            print(f"   ğŸ†” ì¸ìŠ¤í„´ìŠ¤ ID: {id(reranker1)}")
        except Exception as e:
            print(f"   âš ï¸  ë¦¬ë­ì»¤ ëª¨ë¸ ê³µìœ  ì‹¤íŒ¨: {str(e)}")
        
        if is_same_instance:
            print(f"\nâœ… ëª¨ë¸ ê³µìœ  (ì‹±ê¸€í†¤ íŒ¨í„´) ì •ìƒ ì‘ë™!")
        else:
            print(f"\nâš ï¸  ëª¨ë¸ ê³µìœ ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ê³µìœ  í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")


async def test_model_performance_optimization():
    """ëª¨ë¸ ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸"""
    print(f"\nâš¡ ëª¨ë¸ ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # í™˜ê²½ ì„¤ì •
        from app.core.config import settings
        if settings.openai_api_key:
            os.environ['OPENAI_API_KEY'] = settings.openai_api_key
        elif settings.llm_api_key:
            os.environ['OPENAI_API_KEY'] = settings.llm_api_key
        
        from app.core.model_optimization import get_optimized_embedding_model
        from app.core.cache import clear_cache
        
        # ìºì‹œ ì´ˆê¸°í™”
        await clear_cache()
        
        # ìµœì í™”ëœ ì„ë² ë”© ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        embedding_model = get_optimized_embedding_model()
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        test_queries = [
            "MOJI AI ì‹œìŠ¤í…œ",
            "í”„ë¡œì íŠ¸ ê´€ë¦¬ ê¸°ëŠ¥",
            "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤",
            "ë°ì´í„° ë¶„ì„",
            "ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜"
        ]
        
        print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {len(test_queries)}ê°œ")
        print()
        
        # ì²« ë²ˆì§¸ ì‹¤í–‰ (ì½œë“œ ìŠ¤íƒ€íŠ¸)
        print("ğŸ¥¶ ì½œë“œ ìŠ¤íƒ€íŠ¸ ì„±ëŠ¥ (ì²« ì‹¤í–‰)")
        cold_times = []
        
        for i, query in enumerate(test_queries, 1):
            start_time = time.time()
            try:
                # ì„ë² ë”© ìƒì„±
                embedding = embedding_model.embed_query(query)
                elapsed_time = time.time() - start_time
                cold_times.append(elapsed_time)
                
                print(f"   ì¿¼ë¦¬ {i}: {elapsed_time:.3f}ì´ˆ (ë²¡í„° ì°¨ì›: {len(embedding)})")
                
            except Exception as e:
                print(f"   ì¿¼ë¦¬ {i}: âŒ ì˜¤ë¥˜ - {str(e)}")
        
        # ë‘ ë²ˆì§¸ ì‹¤í–‰ (ì›œ ìŠ¤íƒ€íŠ¸)
        print(f"\nğŸ”¥ ì›œ ìŠ¤íƒ€íŠ¸ ì„±ëŠ¥ (ì¬ì‹¤í–‰)")
        warm_times = []
        
        for i, query in enumerate(test_queries, 1):
            start_time = time.time()
            try:
                # ì„ë² ë”© ìƒì„± (ìºì‹œëœ ê²°ê³¼ í™œìš©)
                embedding = embedding_model.embed_query(query)
                elapsed_time = time.time() - start_time
                warm_times.append(elapsed_time)
                
                print(f"   ì¿¼ë¦¬ {i}: {elapsed_time:.3f}ì´ˆ")
                
            except Exception as e:
                print(f"   ì¿¼ë¦¬ {i}: âŒ ì˜¤ë¥˜ - {str(e)}")
        
        # ì„±ëŠ¥ ë¹„êµ
        if cold_times and warm_times:
            avg_cold = sum(cold_times) / len(cold_times)
            avg_warm = sum(warm_times) / len(warm_times)
            improvement = ((avg_cold - avg_warm) / avg_cold) * 100 if avg_cold > 0 else 0
            speedup = avg_cold / avg_warm if avg_warm > 0 else float('inf')
            
            print(f"\nğŸ“Š ì„±ëŠ¥ ë¹„êµ:")
            print(f"   í‰ê·  ì½œë“œ ìŠ¤íƒ€íŠ¸: {avg_cold:.3f}ì´ˆ")
            print(f"   í‰ê·  ì›œ ìŠ¤íƒ€íŠ¸: {avg_warm:.3f}ì´ˆ")
            print(f"   ì„±ëŠ¥ í–¥ìƒ: {improvement:.1f}%")
            print(f"   ì†ë„ í–¥ìƒ: {speedup:.1f}x")
            
            if improvement > 50:
                print(f"   âœ… ìºì‹± íš¨ê³¼ ìš°ìˆ˜!")
            elif improvement > 20:
                print(f"   ğŸ”„ ìºì‹± íš¨ê³¼ ì–‘í˜¸")
            else:
                print(f"   âš ï¸  ìºì‹± íš¨ê³¼ ì œí•œì ")
        
    except Exception as e:
        print(f"âŒ ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()


async def test_startup_initialization():
    """ì‹œì‘ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸš€ ì‹œì‘ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    try:
        from app.core.startup import initialize_moji_system, startup_manager
        
        # ì „ì²´ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        print("ğŸ”§ MOJI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        initialization_results = await initialize_moji_system()
        
        # ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“Š ì´ˆê¸°í™” ê²°ê³¼:")
        print(f"   ì„±ê³µ: {'âœ…' if initialization_results.get('success', False) else 'âŒ'}")
        print(f"   ì´ ì‹œê°„: {initialization_results.get('total_time', 0):.3f}ì´ˆ")
        print(f"   ì™„ë£Œëœ ì‘ì—…: {len(initialization_results.get('tasks_completed', []))}ê°œ")
        print(f"   ì‹¤íŒ¨í•œ ì‘ì—…: {len(initialization_results.get('tasks_failed', []))}ê°œ")
        
        # ìƒì„¸ ì •ë³´
        if initialization_results.get('details'):
            print(f"\nğŸ“‹ ì‘ì—… ìƒì„¸:")
            for task, detail in initialization_results['details'].items():
                print(f"   {task}: {detail}")
        
        # ìš”ì•½ ì •ë³´ ì¶œë ¥
        summary = startup_manager.get_startup_summary(initialization_results)
        print(f"\n{summary}")
        
    except Exception as e:
        print(f"âŒ ì‹œì‘ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")


async def test_memory_optimization():
    """ë©”ëª¨ë¦¬ ìµœì í™” í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ’¾ ë©”ëª¨ë¦¬ ìµœì í™” í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    try:
        import psutil
        import gc
        from app.core.model_optimization import model_manager
        
        # ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        process = psutil.Process()
        memory_before = process.memory_info().rss / 1024 / 1024  # MB
        
        print(f"ğŸ“Š ìµœì í™” ì „ ë©”ëª¨ë¦¬: {memory_before:.1f} MB")
        
        # ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰
        print("ğŸ§¹ ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰ ì¤‘...")
        start_time = time.time()
        
        model_manager.optimize_memory()
        gc.collect()  # ì¶”ê°€ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        
        optimization_time = time.time() - start_time
        
        # ìµœì í™” í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        memory_after = process.memory_info().rss / 1024 / 1024  # MB
        memory_saved = memory_before - memory_after
        memory_reduction = (memory_saved / memory_before) * 100 if memory_before > 0 else 0
        
        print(f"ğŸ“Š ìµœì í™” í›„ ë©”ëª¨ë¦¬: {memory_after:.1f} MB")
        print(f"ğŸ’¾ ì ˆì•½ëœ ë©”ëª¨ë¦¬: {memory_saved:.1f} MB ({memory_reduction:.1f}%)")
        print(f"â±ï¸  ìµœì í™” ì‹œê°„: {optimization_time:.3f}ì´ˆ")
        
        if memory_reduction > 10:
            print(f"âœ… ë©”ëª¨ë¦¬ ìµœì í™” íš¨ê³¼ ìš°ìˆ˜!")
        elif memory_reduction > 5:
            print(f"ğŸ”„ ë©”ëª¨ë¦¬ ìµœì í™” íš¨ê³¼ ì–‘í˜¸")
        else:
            print(f"âš ï¸  ë©”ëª¨ë¦¬ ìµœì í™” íš¨ê³¼ ì œí•œì ")
    
    except ImportError:
        print("âš ï¸  psutil íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ë©”ëª¨ë¦¬ ì¸¡ì •ì„ ìƒëµí•©ë‹ˆë‹¤")
    except Exception as e:
        print(f"âŒ ë©”ëª¨ë¦¬ ìµœì í™” í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")


if __name__ == "__main__":
    async def main():
        await test_model_warm_up()
        await test_model_sharing()
        await test_model_performance_optimization()
        await test_startup_initialization()
        await test_memory_optimization()
        
        print(f"\nğŸ‰ ëª¨ë“  ëª¨ë¸ ìµœì í™” í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ğŸ’¡ ëª¨ë¸ ì˜ˆì—´, ê³µìœ , ìºì‹±ì„ í†µí•´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    asyncio.run(main())