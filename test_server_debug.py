#!/usr/bin/env python3
"""
MOJI ì„œë²„ ë””ë²„ê·¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ë¬¸ì œë¥¼ ì§„ë‹¨í•˜ê³  í•´ê²°í•˜ê¸° ìœ„í•œ í…ŒìŠ¤íŠ¸
"""

import os
import sys
import asyncio
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

async def test_llm_router():
    """LLM Router ì§ì ‘ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” LLM Router í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        from app.llm.router import llm_router
        from langchain_core.messages import HumanMessage
        
        # ì´ˆê¸°í™”
        print("- LLM Router ì´ˆê¸°í™” ì¤‘...")
        await llm_router.initialize()
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ")
        
        # í˜„ì¬ ì„¤ì • í™•ì¸
        print(f"- í˜„ì¬ Provider: {llm_router.config.provider}")
        print(f"- í˜„ì¬ Model: {llm_router.config.model}")
        print(f"- API Key ì„¤ì •: {'âœ…' if llm_router.config.api_key else 'âŒ'}")
        
        # í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ìƒì„±
        print("\nğŸ“¤ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡...")
        messages = [HumanMessage(content="ì•ˆë…•í•˜ì„¸ìš”! í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.")]
        
        # ì‘ë‹µ ìƒì„±
        response = await llm_router.generate(messages=messages)
        print(f"ğŸ“¥ ì‘ë‹µ: {response.content}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

async def test_env_settings():
    """í™˜ê²½ ì„¤ì • í™•ì¸"""
    print("\nğŸ” í™˜ê²½ ì„¤ì • í™•ì¸...")
    
    try:
        from app.core.config import settings
        
        print(f"- LLM Provider: {settings.llm_provider}")
        print(f"- LLM Model: {settings.llm_model}")
        print(f"- API Key ê¸¸ì´: {len(settings.llm_api_key) if settings.llm_api_key else 0}")
        print(f"- API Base: {settings.llm_api_base}")
        
        # .env íŒŒì¼ í™•ì¸
        env_path = Path(".env")
        if env_path.exists():
            print(f"âœ… .env íŒŒì¼ ì¡´ì¬: {env_path.absolute()}")
            
            # API í‚¤ í™•ì¸
            with open(env_path, 'r') as f:
                content = f.read()
                if 'sk-' in content:
                    print("âœ… OpenAI API í‚¤ í˜•ì‹ í™•ì¸ë¨")
                else:
                    print("âš ï¸ OpenAI API í‚¤ê°€ ì˜¬ë°”ë¥¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤")
        else:
            print("âŒ .env íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            
    except Exception as e:
        print(f"âŒ ì„¤ì • í™•ì¸ ì‹¤íŒ¨: {str(e)}")

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ¤– MOJI ì„œë²„ ë””ë²„ê·¸ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # í™˜ê²½ ì„¤ì • í™•ì¸
    await test_env_settings()
    
    # LLM Router í…ŒìŠ¤íŠ¸
    success = await test_llm_router()
    
    if success:
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ì„œë²„ë¥¼ ë‹¤ì‹œ ì‹œì‘í•´ë³´ì„¸ìš”.")
        print("\në‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì„œë²„ ì‹¤í–‰:")
        print("uvicorn app.main:app --reload --host 0.0.0.0 --port 8000")
    else:
        print("\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        print("\nê°€ëŠ¥í•œ í•´ê²° ë°©ë²•:")
        print("1. .env íŒŒì¼ì˜ LLM_API_KEYê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        print("2. OpenAI API í‚¤ê°€ ìœ íš¨í•œì§€ í™•ì¸")
        print("3. ì¸í„°ë„· ì—°ê²° ìƒíƒœ í™•ì¸")

if __name__ == "__main__":
    asyncio.run(main())